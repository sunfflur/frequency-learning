{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "smXRCRKE3gGt",
        "HigUGf251YUT",
        "d5zmiCoeYsLd",
        "7QJ3UMKYEI1_",
        "mB8Nz4YrTdoJ",
        "ALpIaYi7tQTz",
        "8ToOfeyCl2wb",
        "kt_QWBMqqMO7",
        "gEMdJWf2lbjx"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPAwAKMvy/ohBO+Yc5cOZ1S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunfflur/frequency-learning/blob/master/EyeQ/Exp_EyeQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0GGocS93vIn"
      },
      "source": [
        "### Experiment EyeQ database\n",
        "\n",
        "> In this experiment, two classes of the EyeQ dataset were explored: good and reject.\n",
        "\n",
        "> Considering these two classes, 22,358 images were used for training and evaluating\n",
        "the models, according to the following division:\n",
        "\n",
        "----- Training set – 8,347 images of good category and 2,320 images of reject category;\n",
        "\n",
        "----- Validation set – 8,471 images of good category and 3,220 images of reject category.\n",
        "\n",
        "`Author:` [sunfflur](https://github.com/sunfflur)\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smXRCRKE3gGt"
      },
      "source": [
        "#### Libraries Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oot4s_fB3W5F",
        "outputId": "1d7a4c9e-e08c-46d6-ab12-608aa17099fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autokeras\n",
            "  Downloading autokeras-1.0.20-py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from autokeras) (1.3.5)\n",
            "Collecting keras-tuner>=1.1.0\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 104.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from autokeras) (21.3)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from autokeras) (2.9.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (7.9.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.23.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (4.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.19.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.28.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.1.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.50.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.4.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 78.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner>=1.1.0->autokeras) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->autokeras) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->autokeras) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner, autokeras\n",
            "Successfully installed autokeras-1.0.20 jedi-0.18.2 keras-tuner-1.1.3 kt-legacy-1.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 13.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-recommenders\n",
            "  Downloading tensorflow_recommenders-0.7.2-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow-recommenders) (1.3.0)\n",
            "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-recommenders) (2.9.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (4.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (21.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.28.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.9.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.1.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.9.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.50.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow-recommenders) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.4.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow>=2.9.0->tensorflow-recommenders) (3.0.9)\n",
            "Installing collected packages: tensorflow-recommenders\n",
            "Successfully installed tensorflow-recommenders-0.7.2\n"
          ]
        }
      ],
      "source": [
        "s = 23\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(s)\n",
        "import random\n",
        "random.seed(s)\n",
        "from numpy.random import seed\n",
        "seed(s)\n",
        "import tensorflow as tf\n",
        "#import tensorflow\n",
        "tf.random.set_seed(s)\n",
        "#from tensorflow.random import set_seed\n",
        "#set_seed(s)\n",
        "\n",
        "import PIL\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.layers import Layer, Dense, Conv1D, Dropout, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.utils import to_categorical, image_dataset_from_directory\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import time\n",
        "\n",
        "!pip install autokeras\n",
        "!pip install tensorflow-addons \n",
        "!pip install tensorflow-recommenders\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n0D9z1XL5xV",
        "outputId": "bcea2145-b607-40f1-c381-c2200e83b556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec  5 18:01:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0    29W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tk7Kjs6Mmsa",
        "outputId": "d3d0f4d7-aa0f-4eef-dd36-9753a709bd63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Drive mount"
      ],
      "metadata": {
        "id": "HigUGf251YUT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TIae5wrXgh9",
        "outputId": "5541e13c-2078-4a83-917a-85811aa29738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: www-browser: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links2: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: elinks: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: lynx: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=t8P3pSQ5kuACoAQ6eH9QBzn2KgEGLh5lboJsYQ8vCIo'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=t8P3pSQ5kuACoAQ6eH9QBzn2KgEGLh5lboJsYQ8vCIo\")\n"
          ]
        }
      ],
      "source": [
        "### TESSSSSST ###\n",
        "\n",
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjJPKK3rYKR3",
        "outputId": "0a0f674d-979a-4bdf-8a14-9eda5f7d0829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package w3m.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 124020 files and directories currently installed.)\n",
            "Preparing to unpack .../w3m_0.5.3-36build1_amd64.deb ...\n",
            "Unpacking w3m (0.5.3-36build1) ...\n",
            "Setting up w3m (0.5.3-36build1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5zmiCoeYsLd"
      },
      "source": [
        "#### Image Main Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zljpn9-1yqxe"
      },
      "outputs": [],
      "source": [
        "### blocks ###\n",
        "def slice(image, levels):\n",
        "  if levels == 0:\n",
        "    image = tf.transpose(image, [0, 3, 1, 2])\n",
        "    return image\n",
        "  iM, iN = image.shape[1], image.shape[2]\n",
        "  iMc, iNc = int(iM/2), int(iN/2)\n",
        "  output = tf.stack((image[:, :iMc, :iNc], image[:, :iMc,iNc:], image[:, iMc:,:iNc], image[:, iMc:, iNc:]),-1)\n",
        "  output = tf.reshape(output,[output.shape[0],output.shape[1],output.shape[2],-1])\n",
        "  return slice(output, levels-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp05k1xgsGcZ"
      },
      "outputs": [],
      "source": [
        "### DFT ### \n",
        "def m_spectrum(image):\n",
        "  side = image.shape[2]\n",
        "  inputx = tf.cast(image, tf.complex128) # change dtype to complex64 \n",
        "  fft = tf.signal.fft2d(inputx) # perform fast fourier transform\n",
        "  fft_shift = tf.signal.fftshift(fft, axes=(2,3)) # shift the zero-frequency component to the center\n",
        "\n",
        "  # calculate the magnitude and scale it\n",
        "  magnitude = tf.math.abs(fft_shift) \n",
        "  magnitude = tf.math.divide(magnitude, side**2)\n",
        "  magnitude = tf.math.log(1+magnitude)\n",
        "\n",
        "  return magnitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUS7GW0c52xo"
      },
      "outputs": [],
      "source": [
        "### magnitude sums ###\n",
        "def radial_grouping(image, r):\n",
        "  iM, iN = image.shape[2], image.shape[3] #image dimension\n",
        "  iMc, iNc = int(iM/2), int(iN/2) #image center\n",
        "  A = tf.range(-iMc,iNc)**2\n",
        "  dists = tf.math.sqrt(tf.cast(A[:,None] + A, dtype=tf.float32))\n",
        "  dists = tf.reshape(dists, [1,1,image.shape[2],image.shape[3]]) #1,1,128,128\n",
        "  n = int(iNc/r) #rings number\n",
        "  r = (r/2)\n",
        "  magnitude_sums = []\n",
        "  ring = 0\n",
        "  for j in range(1, 2*n, 2):\n",
        "    ring = tf.cast((tf.abs(dists-r*j)<r), dtype=tf.float32)\n",
        "    if j == 1:\n",
        "      ring = tf.cast((tf.abs(dists-(r/2)*j)<=(r/2)), dtype=tf.float32)\n",
        "    mult = tf.multiply(ring,image)\n",
        "    sum = tf.reduce_sum(mult,axis=(2,3))\n",
        "    magnitude_sums.append(sum.numpy())\n",
        "  magnitude_sums = tf.transpose(tf.convert_to_tensor(magnitude_sums))\n",
        "  magnitude_sums = tf.reshape(magnitude_sums, [magnitude_sums.shape[1], magnitude_sums.shape[2], magnitude_sums.shape[0]])\n",
        "  magnitude_sums = tf.reshape(magnitude_sums, [magnitude_sums.shape[0], -1])\n",
        "  return magnitude_sums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqYfzCMk06Tw"
      },
      "outputs": [],
      "source": [
        "### magnitude sums ###\n",
        "def square_grouping(image, r):\n",
        "  iM, iN = image.shape[2], image.shape[3] #img.shape\n",
        "  iMc, iNc = int(iM/2), int(iN/2) #image center\n",
        "  n = int(iNc/r) #rings number\n",
        "  ring = np.full((iM,iN), 0)\n",
        "  magnitude_sums = []\n",
        "  for w in range(r, (n*r)+1, r):\n",
        "    ring[iMc-w:iMc+w,iNc-w:iNc+w] = 1\n",
        "    ring[iMc-w + r :iMc+w -r ,iNc-w +r :iNc+w -r] = 0\n",
        "    mult = tf.multiply(ring,image)\n",
        "    sum = tf.reduce_sum(mult,axis=(2,3))\n",
        "    magnitude_sums.append(sum.numpy())\n",
        "  magnitude_sums = tf.transpose(tf.convert_to_tensor(magnitude_sums))\n",
        "  magnitude_sums = tf.reshape(magnitude_sums, [magnitude_sums.shape[1], magnitude_sums.shape[2], magnitude_sums.shape[0]])\n",
        "  magnitude_sums = tf.reshape(magnitude_sums, [magnitude_sums.shape[0], -1])\n",
        "  return magnitude_sums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QJ3UMKYEI1_"
      },
      "source": [
        "#### Image Main Functions - Per Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpRwOHaJEI2i"
      },
      "outputs": [],
      "source": [
        "### blocks PER IMAGE ###\n",
        "def slice_data(images, levels):\n",
        "  outputs = []\n",
        "  if levels == 0:\n",
        "    dim = int(tf.rank(images))\n",
        "    if dim == 3:\n",
        "      #print(images.shape)\n",
        "      images = tf.expand_dims(images, -1)\n",
        "      images = tf.transpose(images, [0, 3, 1, 2])\n",
        "      return images\n",
        "    else:\n",
        "      images = tf.transpose(images, [0, 3, 1, 2])\n",
        "      return images\n",
        "  for image in images:\n",
        "    #print('image shape?', image.shape)\n",
        "    iM, iN = image.shape[0], image.shape[1] #512,512\n",
        "    iMc, iNc = int(iM/2), int(iN/2) #512/2,512/2\n",
        "    output = tf.stack((image[:iMc, :iNc], image[:iMc,iNc:], image[iMc:,:iNc], image[iMc:, iNc:]),-1)\n",
        "    output = tf.reshape(output,[output.shape[0],output.shape[1], -1]) #256,256,4\n",
        "    outputs.append(output)\n",
        "  outputs = tf.convert_to_tensor(outputs)\n",
        "  return slice_data(outputs, levels-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALSxI6H0EI2j"
      },
      "outputs": [],
      "source": [
        "### DFT PER IMAGE ### \n",
        "def m_spectrum(images):\n",
        "  magnitudes = []\n",
        "  for image in images:\n",
        "    side = image.shape[1]\n",
        "    inputx = tf.cast(image, tf.complex128) # change dtype to complex64\n",
        "    fft = tf.signal.fft2d(inputx) # perform fast fourier transform\n",
        "    fft_shift = tf.signal.fftshift(fft, axes=(1,2)) # shift the zero-frequency component to the center\n",
        "    # calculate the magnitude and scale it\n",
        "    magnitude = tf.math.abs(fft_shift)\n",
        "    magnitude = tf.math.divide(magnitude, side**2) # do not change here !!!\n",
        "    magnitude = tf.math.log(1+magnitude)\n",
        "    magnitudes.append(magnitude)\n",
        "  return tf.convert_to_tensor(magnitudes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TFsMW1vZbtI"
      },
      "outputs": [],
      "source": [
        "def NormalizeData(X, max=1, min=0):\n",
        "    ### data normalization between 0-1\n",
        "    X_std = (X - tf.math.reduce_min(X)) / (tf.math.reduce_max(X) - tf.math.reduce_min(X))\n",
        "    X_scaled = X_std * (max - min) + min\n",
        "    return X_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jt0CZV-WYnY"
      },
      "outputs": [],
      "source": [
        "def DHT(images):\n",
        "  fhts = []\n",
        "  for image in images:\n",
        "    side = image.shape[1]\n",
        "    inputx = tf.cast(image, tf.complex128) # change dtype to complex64\n",
        "    #print('inputx', inputx.shape)\n",
        "    fft = tf.signal.fft2d(inputx) # perform fast fourier transform\n",
        "    fft_shift = tf.signal.fftshift(fft, axes=(1,2)) # shift the zero-frequency component to the center\n",
        "    real = tf.math.real(fft_shift)\n",
        "    imag = tf.math.imag(fft_shift)\n",
        "\n",
        "    # calculate the hartley transform from the real and imaginary parts of the FFT\n",
        "    FHT = real - imag\n",
        "    FHT = tf.math.divide(FHT, side**2)\n",
        "    #FHT = tf.math.sign(FHT)*tf.math.log(tf.math.abs(FHT)+1)\n",
        "    FHT = tf.math.abs(tf.math.asinh(FHT))\n",
        "    #FHT = tf.math.asinh(FHT)\n",
        "    fhts.append(FHT)\n",
        "  return tf.convert_to_tensor(fhts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROQy9_tcEI2l"
      },
      "outputs": [],
      "source": [
        "### magnitude sums PER IMAGE ###\n",
        "def radial_grouping(images, r):\n",
        "  grouping = []\n",
        "  for image in images:\n",
        "    iM, iN = image.shape[1], image.shape[2] #image dimension\n",
        "    iMc, iNc = int(iM/2), int(iN/2) #image center\n",
        "    A = tf.range(-iMc,iNc)**2\n",
        "    dists = tf.math.sqrt(tf.cast(A[:,None] + A, dtype=tf.float64))\n",
        "    dists = tf.reshape(dists, [1,image.shape[1],image.shape[2]]) #1,512,512\n",
        "    n = int(iNc/r) #rings number\n",
        "    magnitude_sums = []\n",
        "    ring = 0\n",
        "    for j in range(1, 2*n, 2):\n",
        "      ring = tf.cast((tf.abs(dists-(r/2)*j)<(r/2)), dtype=tf.float64)\n",
        "      if j == 1:\n",
        "        ring = tf.cast((tf.abs(dists-(r/2)*j)<=(r/2)), dtype=tf.float64)\n",
        "      mult = tf.multiply(ring,image)\n",
        "      sum = tf.reduce_sum(mult,axis=(1,2))\n",
        "      magnitude_sums.append(sum.numpy())\n",
        "    magnitude_sums = tf.convert_to_tensor(magnitude_sums)\n",
        "    grouping.append(magnitude_sums)\n",
        "  grouping = tf.convert_to_tensor(grouping)\n",
        "  grouping = tf.reshape(grouping, [grouping.shape[0], -1])\n",
        "  return grouping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOR9FVA11Fzc"
      },
      "outputs": [],
      "source": [
        "### magnitude sums PER IMAGE ###\n",
        "def square_grouping(images, r):\n",
        "  grouping = []\n",
        "  for image in images:\n",
        "    iM, iN = image.shape[1], image.shape[2] #image dimension\n",
        "    iMc, iNc = int(iM/2), int(iN/2) #image center\n",
        "    A = tf.range(-iMc,iNc)**2\n",
        "    n = int(iNc/r) #rings number\n",
        "    ring = np.full((iM,iN), 0)\n",
        "    magnitude_sums = []\n",
        "    for w in range(r, (n*r)+1, r):\n",
        "      ring[iMc-w:iMc+w,iNc-w:iNc+w] = 1\n",
        "      ring[iMc-w + r :iMc+w -r ,iNc-w +r :iNc+w -r] = 0\n",
        "      mult = tf.multiply(ring, image)\n",
        "      #print('mult:', mult)\n",
        "      sum = tf.reduce_sum(mult,axis=(1,2))\n",
        "      magnitude_sums.append(sum.numpy())\n",
        "    magnitude_sums = tf.convert_to_tensor(magnitude_sums)\n",
        "    grouping.append(magnitude_sums)\n",
        "  grouping = tf.convert_to_tensor(grouping)\n",
        "  grouping = tf.reshape(grouping, [grouping.shape[0], -1])\n",
        "  return grouping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB8Nz4YrTdoJ"
      },
      "source": [
        "#### Custom Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M1kn11dFT0bx"
      },
      "outputs": [],
      "source": [
        "### frequency layer constrution ###\n",
        "\n",
        "class FreqLayer(Layer):\n",
        "  def __init__(self, units, kernel_initializer='RandomNormal', extra_layers='Dense', output_type='Dense', **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.units = units\n",
        "    self.kernel_initializer = kernel_initializer\n",
        "    self.extra_layers = extra_layers\n",
        "    self.output_type = output_type\n",
        "  def get_config(self):\n",
        "    config = super(FreqLayer, self).get_config()\n",
        "    config.update({\n",
        "      \"units\": self.units,\n",
        "      \"kernel_initializer\": self.kernel_initializer,\n",
        "      \"extra_layers\": self.extra_layers,\n",
        "      \"output_type\": self.output_type\n",
        "      })\n",
        "    return config\n",
        "  def build(self, batch_input_shape):\n",
        "    if self.extra_layers == 'Dense':\n",
        "      shape = [batch_input_shape[-1]] #(weights,) - shape for dense training\n",
        "    else:\n",
        "      shape = [batch_input_shape[-2],1] #(weights, 1) - shape for convolutional training\n",
        "    self.kernel = self.add_weight(\n",
        "        name='kernel',\n",
        "        shape = shape,\n",
        "        initializer=self.kernel_initializer,\n",
        "        trainable=True)\n",
        "    super().build(batch_input_shape) # must be at the end\n",
        "  def call(self, X):\n",
        "    #### fourier convolution ####\n",
        "    f = X*self.kernel\n",
        "\n",
        "    #### hartley convolution ####\n",
        "    #f = conv(X, self.kernel)\n",
        "\n",
        "    return f\n",
        "  def compute_output_shape(self, batch_input_shape):\n",
        "    if self.output_type == 'Dense':\n",
        "      return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units]) #[examples,1] - dense\n",
        "    else:\n",
        "      return tf.TensorShape(batch_input_shape.as_list()[:-2] + [self.units]) #[examples,1] - conv1d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALpIaYi7tQTz"
      },
      "source": [
        "#### Data Load Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5o2BCua1szdV"
      },
      "outputs": [],
      "source": [
        "\"\"\"#### Data Load\"\"\"\n",
        "\n",
        "### Saved Pre-Processed data LOAD ###\n",
        "\n",
        "def Load(path_train=None, y_train=None, path_valid=None, y_valid=None, path_test=None, y_test=None, extra_layers='Dense'):\n",
        "  y_train, y_test = tf.stack(np.load(y_train)), tf.stack(np.load(y_test))\n",
        "  if extra_layers=='Dense':\n",
        "    if path_valid!=False:\n",
        "      input_train = tf.convert_to_tensor(np.load(path_train)) ### train \n",
        "      input_valid = tf.convert_to_tensor(np.load(path_valid)) ### valid\n",
        "      input_test = tf.convert_to_tensor(np.load(path_test)) ### test\n",
        "      return input_train, y_train, input_valid, y_valid, input_test, y_test\n",
        "    else:\n",
        "      input_train = tf.convert_to_tensor(np.load(path_train)) ### train \n",
        "      input_test = tf.convert_to_tensor(np.load(path_test)) ### test\n",
        "      return input_train, y_train, input_test, y_test\n",
        "  else:\n",
        "    if path_valid!=False:\n",
        "      input_train = tf.convert_to_tensor(np.load(path_train)) ### train \n",
        "      input_train = tf.expand_dims(input_train, -1)\n",
        "      input_valid = tf.convert_to_tensor(np.load(path_valid)) ### valid\n",
        "      input_valid = tf.expand_dims(input_valid, -1)\n",
        "      input_test = tf.convert_to_tensor(np.load(path_test)) ### test\n",
        "      input_test = tf.expand_dims(input_test, -1)\n",
        "      return input_train, y_train, input_valid, y_valid, input_test, y_test\n",
        "    else:\n",
        "      input_train = tf.convert_to_tensor(np.load(path_train)) ### train \n",
        "      input_train = tf.expand_dims(input_train, -1)\n",
        "      input_test = tf.convert_to_tensor(np.load(path_test)) ### test\n",
        "      input_test = tf.expand_dims(input_test, -1)\n",
        "      return input_train, y_train, input_test, y_test\n",
        "  #return input_train, input_valid, input_test\n",
        "\n",
        "\n",
        "def input_split(x=None, image_shape=None, levels=3, ch=1):\n",
        "  coefs1 = int((image_shape/2)/2) #\n",
        "  #ch = 3 #channels\n",
        "\n",
        "  # layer 3 (global)\n",
        "  C = x[:, 0:coefs1*ch] #TensorShape([3360, 384])\n",
        "\n",
        "  # layer 2\n",
        "  B = x[:, coefs1*ch:(coefs1*ch)+(2*coefs1*ch)] #TensorShape([3360, 768])\n",
        "\n",
        "  # layer 1 (local)\n",
        "  A = x[:, (coefs1*ch)+(2*coefs1*ch):(coefs1*ch)+(2*coefs1*ch)+(4*coefs1*ch)] #TensorShape([3360, 1536]) \n",
        "\n",
        "  return A, B, C"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plots"
      ],
      "metadata": {
        "id": "8ToOfeyCl2wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def my_violin_plot(data_to_plot, labels=['A', 'B'], xlabel='Sample name', ylabel='Observed values', title='Title', cm='Pastel2_r',\n",
        "                   savefig_path=None):\n",
        "\n",
        "    # Create a figure instance\n",
        "    fig = plt.figure(figsize=(9,4))\n",
        "    \n",
        "    quartile1, medians, quartile3 = np.percentile(data_to_plot, [25, 50, 75], axis=1) #axis=0\n",
        "    inds = np.arange(1, len(medians) + 1)\n",
        "\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.xaxis.set_major_locator(MultipleLocator(1))\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks(np.arange(1, len(labels) + 1), labels=labels)\n",
        "    ax.set_xticklabels(labels)\n",
        "\n",
        "    ax.scatter(inds, medians, marker='o', color='white', s=20, zorder=3)\n",
        "\n",
        "    # Create the boxplot\n",
        "    bp = ax.violinplot(data_to_plot, showmeans=True, showmedians=True)\n",
        "\n",
        "    heights = [violin.get_paths()[0].get_extents().height for violin in bp['bodies']]\n",
        "    norm = plt.Normalize(min(heights), max(heights))\n",
        "    cmap = plt.get_cmap(cm)\n",
        "\n",
        "\n",
        "    # Make all the violin statistics marks red:\n",
        "    for partname in ('cbars','cmins','cmaxes','cmeans','cmedians'):\n",
        "        vp = bp[partname]\n",
        "        vp.set_edgecolor('black')\n",
        "        vp.set_linewidth(0.5)\n",
        "\n",
        "    # Make the violin body a cmap with black borders\n",
        "    for violin, height in zip(bp['bodies'], heights):\n",
        "         violin.set_color(cmap(norm(height)))\n",
        "         violin.set_edgecolor('gray')\n",
        "         violin.set_alpha(1.0)\n",
        "         violin.set_linewidth(0.5)\n",
        "\n",
        "    #plt.colorbar(ScalarMappable(norm=norm, cmap=cmap), alpha=violin.get_alpha(), ax=ax) #label='Violin Extent'\n",
        "    #plt.tight_layout()\n",
        "    plt.savefig(savefig_path)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "### TRAIN/VALIDATION EVOLUTION PLOT ###\n",
        "\n",
        "def evolution_curves_plot(history, language='pt-br'):\n",
        "    if language=='en':\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.plot(history.history['loss'], 'r-', label='Training loss')\n",
        "        plt.plot(history.history['val_loss'], 'r--', label='Validation loss')\n",
        "        plt.plot(history.history['accuracy'], 'g-', label = 'Training accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], 'g--', label = 'Validation accuracy')\n",
        "        plt.xlabel('Epoch', fontsize=14), plt.ylabel('Magnitude', fontsize=14)\n",
        "        plt.title('Loss and Accuracy evolution', fontsize=14)\n",
        "        plt.legend(loc='best')\n",
        "        plt.show()\n",
        "    elif language=='pt-br':\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.plot(history.history['loss'], 'r-', label='Perda de treinamento')\n",
        "        #plt.plot(history.history['val_loss'], 'r--', label='Perda de validação')\n",
        "        plt.plot(history.history['accuracy'], 'g-', label = 'Acurácia de treinamento')\n",
        "        #plt.plot(history.history['val_accuracy'], 'g--', label = 'Acurácia de validação')\n",
        "        plt.xlabel('Época', fontsize=14), plt.ylabel('Magnitude', fontsize=14)\n",
        "        plt.title('Evolução de perda e acurácia', fontsize=14)\n",
        "        plt.legend(loc='best')\n",
        "        plt.show()\n",
        "\n",
        "### CONFUSION MATRIX PLOT ###\n",
        "\n",
        "def confusion_matrix_plot(data, y_test, model, language='pt-br'): \n",
        "    y_pred = model.predict(data)\n",
        "    plt.figure(figsize = (12,8))\n",
        "    cm = confusion_matrix(tf.argmax(y_test, axis=1), tf.argmax(y_pred, axis=1))\n",
        "    acc = np.trace(cm)/data.shape[0] * 100\n",
        "    erros = tf.reduce_sum(cm)-tf.linalg.trace(cm)\n",
        "    if language=='en':\n",
        "        plt.title('Test set - accuracy %.2f%% / %d incorrect classifications' % (acc, erros), fontsize=14)\n",
        "    elif language=='pt-br':\n",
        "        plt.title('Conjunto de teste - %.2f%% de acurácia / %d classificações incorretas' % (acc, erros), fontsize=14)\n",
        "    labels = ['good','reject']\n",
        "    sn.heatmap(cm, cmap='Pastel1_r', linewidths=.1, annot=True, fmt=\".6g\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('y_pred',fontsize=14)\n",
        "    plt.ylabel('y_test',fontsize=14)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.show()\n",
        "\n",
        "### INCORRECT CLASSIFICATION EXAMPLES PLOT ###\n",
        "\n",
        "def incorrect_class_plot(data, x_test, y_test, model):\n",
        "    dic = {0:'blanket1',1:'blanket2',2:'canvas1',3:'ceiling1',4:'ceiling2',5:'cushion1',\n",
        "           6:'floor1',7:'floor2',8:'grass1',9:'lentils1',10:'linseeds1',11:'oatmeal1',\n",
        "           12:'pearlsugar1',13:'rice1',14:'rice2',15:'rug1',16:'sand1',17:'scarf1',\n",
        "           18:'scarf2',19:'screen1',20:'seat1',21:'seat2',22:'sesameseeds1',23:'stone1',\n",
        "           24:'stone2',25:'stone3',26:'stoneslab1',27:'wall1'}\n",
        "\n",
        "    y_pred = model.predict(data)\n",
        "    dif = tf.argmax(y_test, axis=1)-tf.argmax(y_pred, axis=1)\n",
        "    indices = np.where(dif!=0)[0]\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.subplot(121), plt.imshow(tf.squeeze(x_test[indices[0]]), cmap='gray')\n",
        "    r1 = tf.argmax(y_test, axis=1)[indices[0]]\n",
        "    f1 = tf.argmax(y_pred, axis=1)[indices[0]]\n",
        "    p1=np.amax((y_pred)[indices[0]])\n",
        "\n",
        "    #t1 = \"Actual class = {}\\nPredicted class = {}\\nPrediction probability = {:.2f} %\" \\\n",
        "    #            .format(dic[int(r1)], dic[int(f1)], p1*100)\n",
        "    t1 = \"Classe verdadeira = {}\\nClasse predita = {}\\nProbabilidade de predição = {:.2f} %\" \\\n",
        "                .format(dic[int(r1)], dic[int(f1)], p1*100)\n",
        "    #plt.title('Classe: %s - Predição: %s' % (dic[int(r1)], dic[int(f1)]))\n",
        "    #plt.title('Class: %s - Prediction: %s' % (dic[int(r1)], dic[int(f1)]))\n",
        "    plt.title(t1,fontsize=14)\n",
        "\n",
        "    p2=np.amax((y_pred)[indices[1]])\n",
        "    plt.subplot(122), plt.imshow(tf.squeeze(x_test[indices[1]]), cmap='gray')\n",
        "    r2 = tf.argmax(y_test, axis=1)[indices[1]]\n",
        "    f2 = tf.argmax(y_pred, axis=1)[indices[1]]\n",
        "    #plt.title('Classe: %s - Predição: %s' % (dic[int(r2)], dic[int(f2)]))\n",
        "    #plt.title('Class: %s - Prediction: %s' % (dic[int(r2)], dic[int(f2)]))\n",
        "    #t2 = \"Actual class = {}\\nPredicted class = {}\\nPrediction probability = {:.2f} %\" \\\n",
        "    #            .format(dic[int(r2)], dic[int(f2)], p2*100)\n",
        "    t2 = \"Classe verdadeira = {}\\nClasse predita = {}\\nProbabilidade de predição = {:.2f} %\" \\\n",
        "                .format(dic[int(r2)], dic[int(f2)], p2*100)\n",
        "    plt.title(t2,fontsize=14)\n",
        "    #plt.subplot(133), plt.imshow(tf.squeeze(x_test[indices[2]]), cmap='gray')\n",
        "    #r3 = tf.argmax(y_test, axis=1)[indices[2]]\n",
        "    #f3 = tf.argmax(y_pred, axis=1)[indices[2]]\n",
        "    #plt.title('Classe: %s - Predição: %s' % (dic[int(r3)], dic[int(f3)]))\n",
        "    plt.show()\n",
        "\n",
        "### FREQUENCY LAYER WEIGHTS PLOT ###\n",
        "\n",
        "def freq_weights_plot(model):\n",
        "    plt.figure(figsize=(9,3))\n",
        "    plt.plot(model.get_weights()[0])\n",
        "    #plt.plot(model.get_weights()[1])\n",
        "    #plt.plot(model.get_weights()[2])\n",
        "    #plt.plot(model.get_weights()[3])\n",
        "    plt.title('Camada em frequência',fontsize=14)\n",
        "    #plt.title('Frequency Layer')\n",
        "    plt.xlabel('Raio (r)',fontsize=14), plt.ylabel('Pesos',fontsize=14)\n",
        "    #plt.xlabel('Radius (r)'), plt.ylabel('Weights')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8jRflLbtl6I0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt_QWBMqqMO7"
      },
      "source": [
        "#### Data Pre-Process - 3 levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yApH-nqEMT5r"
      },
      "outputs": [],
      "source": [
        "class PreProcess():\n",
        "  def __init__(self, data, level, r): #level = levels number; r = radius (ring width);\n",
        "    self.data = data #x_train/test\n",
        "    self.level = level\n",
        "    self.r = r\n",
        "  def processing(self):\n",
        "    conc_channels = []\n",
        "    for i in range(0, self.level+1):\n",
        "      print('level:', i)\n",
        "      for j in range(0, self.data.shape[3]):\n",
        "        print('channel:', j)\n",
        "        sliced_data = slice_data(self.data[:,:,:,j], levels=i)\n",
        "        dht_data = DHT(sliced_data)\n",
        "        #dft_data = m_spectrum(sliced_data)\n",
        "        #grouping_data = radial_grouping(dft_data, r=self.r) # r = radius (ring width)\n",
        "        #grouping_data = square_grouping(dft_data, r=self.r) # r = radius (ring width)\n",
        "        grouping_data = square_grouping(dht_data, r=self.r) # r = radius (ring width)\n",
        "        conc_channels.append(grouping_data)\n",
        "        #del sliced_data\n",
        "        #del dht_data\n",
        "        #del grouping_data\n",
        "      conc = tf.concat((conc_channels), axis=1)\n",
        "    input = np.asarray(tf.concat((conc), axis=1))\n",
        "    #input = tf.expand_dims(input, axis=-1)\n",
        "    #print(input.shape)\n",
        "    ### data normalization between 0-1\n",
        "    #scaler = MinMaxScaler()\n",
        "    #inp = scaler.fit_transform(input) #N,weights \n",
        "    inp = NormalizeData(input)\n",
        "    #inp = tf.math.asinh(input)\n",
        "    input = tf.convert_to_tensor(inp)\n",
        "    return input, sliced_data, dht_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pre-processed data LOAD"
      ],
      "metadata": {
        "id": "gEMdJWf2lbjx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "v5jvR6Hps7ge"
      },
      "outputs": [],
      "source": [
        "### Saved Pre-Processed data LOAD ###\n",
        "\n",
        "input_train, y_train, input_test, y_test = Load(path_train='/content/drive/MyDrive/Mestrado/Experimentos/exp-eyeq/exp-eyeq-data/square-grouping/3-levels/input_train_eyeq_l2_w1_square512_fft.npy',\n",
        "                                                y_train='/content/drive/MyDrive/Mestrado/Experimentos/exp-eyeq/exp-eyeq-data/square-grouping/3-levels/y_train.npy',\n",
        "                                                path_valid=False,\n",
        "                                                y_valid=False,\n",
        "                                                path_test='/content/drive/MyDrive/Mestrado/Experimentos/exp-eyeq/exp-eyeq-data/square-grouping/3-levels/input_test_eyeq_l2_w1_square512_fft.npy',\n",
        "                                                y_test='/content/drive/MyDrive/Mestrado/Experimentos/exp-eyeq/exp-eyeq-data/square-grouping/3-levels/y_test.npy',\n",
        "                                                extra_layers='Dense')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoFob9MrnSLi",
        "outputId": "996f01ee-2cd0-4cba-e4ad-74ca3e5c7688"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10667, 5376])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7HTXQ-PnUzw",
        "outputId": "5c480766-a077-4797-d622-8cf470b4074f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([11691, 5376])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ],
      "metadata": {
        "id": "UwIAfaeRY3HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracies = []\n",
        "total_times = []\n",
        "mean = []\n",
        "t_mean = []\n",
        "\n",
        "optimizers = ['Adam']\n",
        "for index, opt in enumerate(optimizers):\n",
        "    print('>>> current optimizer:', opt)\n",
        "    acc = []\n",
        "    tempos = []\n",
        "    for m in range(0, 1):\n",
        "        print(\">>>>>>>>>> test:\", m)\n",
        "        ### reset session ###\n",
        "        tf.keras.backend.clear_session()\n",
        "        ### dense ###\n",
        "        tf.random.set_seed(0) #s\n",
        "        init = 'glorot_normal' #glorot_normal\n",
        "        function = 'LeakyReLU' #LeakyReLU\n",
        "        model = Sequential([\n",
        "        FreqLayer(1, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=0.01)), #0.01\n",
        "        Dense(64, activation=function, #128 original\n",
        "              kernel_initializer=init, bias_initializer=init),\n",
        "        Dropout(0.25), #0.25\n",
        "        Dense(32, activation=function, #128\n",
        "             kernel_initializer=init, bias_initializer=init),\n",
        "        Dropout(0.15),  #0.15\n",
        "        Dense(32, activation=function, \n",
        "             kernel_initializer=init, bias_initializer=init),    \n",
        "        Dense(2, activation='softmax')])\n",
        "        \n",
        "        \"\"\" Optimizers \"\"\"\n",
        "\n",
        "        ### inverse time decay  ###\n",
        "        bs=32 #32\n",
        "        inversetime_decay = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "          initial_learning_rate = 0.01, #0.01\n",
        "          decay_steps = input_train.shape[0]/bs,\n",
        "          decay_rate = 0.01) #0.01\n",
        "\n",
        "        ### optimizers ###\n",
        "        d_m=0.9 #momentum - dense layers 0.8\n",
        "\n",
        "        if opt == 'Adam':\n",
        "            opt = Adam(learning_rate=0.001, amsgrad=True) #0.001\n",
        "        elif opt == 'SGD':\n",
        "            opt = tfrs.experimental.optimizers.CompositeOptimizer([\n",
        "                  (SGD(learning_rate=inversetime_decay, momentum=0.0), lambda: [model.layers[0].kernel]),\n",
        "                  (SGD(learning_rate=inversetime_decay, momentum=d_m), lambda: model.layers[1].weights),\n",
        "                  (SGD(learning_rate=inversetime_decay, momentum=d_m), lambda: model.layers[2].weights),\n",
        "                  (SGD(learning_rate=inversetime_decay, momentum=d_m), lambda: model.layers[3].weights),\n",
        "                  (SGD(learning_rate=inversetime_decay, momentum=d_m), lambda: model.layers[4].weights),\n",
        "                  (SGD(learning_rate=inversetime_decay, momentum=d_m), lambda: model.layers[5].weights),   \n",
        "                  (SGD(learning_rate=inversetime_decay, momentum=d_m), lambda: model.layers[6].weights)])\n",
        "        \n",
        "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        inicio = time.time()\n",
        "        history =  model.fit(input_train, y_train, epochs=700, batch_size=bs, verbose=2, shuffle=True, validation_split=0.05)\n",
        "        fim = time.time()\n",
        "        tempo = fim-inicio\n",
        "        print(\"time:\", tempo)\n",
        "\n",
        "        ### TEST ACC ###\n",
        "        scores = model.evaluate(input_test, y_test)\n",
        "        print('\\ntest %s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n",
        "        acc.append(scores[1])\n",
        "        tempos.append(tempo)\n",
        "    accuracies = tf.convert_to_tensor(acc)\n",
        "    t = tf.convert_to_tensor(tempos)\n",
        "    mean.append(tf.reduce_mean(accuracies))\n",
        "    t_mean.append(tf.reduce_mean(t))\n",
        "    test_accuracies.append(accuracies)\n",
        "    total_times.append(t)\n",
        "    \n",
        "print('test_accuracies:', test_accuracies) #SGD and Adam\n",
        "print('mean accuracy:', mean)\n",
        "print('total_time:', total_times) #SGD and Adam\n",
        "print('mean time:', t_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM60m9hUY1p-",
        "outputId": "acab1488-6ca1-4e68-9063-382022337f2c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> current optimizer: Adam\n",
            ">>>>>>>>>> test: 0\n",
            "Epoch 1/700\n",
            "317/317 - 2s - loss: 0.3113 - accuracy: 0.8711 - val_loss: 0.0774 - val_accuracy: 0.9831 - 2s/epoch - 6ms/step\n",
            "Epoch 2/700\n",
            "317/317 - 1s - loss: 0.1164 - accuracy: 0.9646 - val_loss: 0.0958 - val_accuracy: 0.9682 - 957ms/epoch - 3ms/step\n",
            "Epoch 3/700\n",
            "317/317 - 1s - loss: 0.1028 - accuracy: 0.9701 - val_loss: 0.0654 - val_accuracy: 0.9794 - 952ms/epoch - 3ms/step\n",
            "Epoch 4/700\n",
            "317/317 - 1s - loss: 0.0939 - accuracy: 0.9715 - val_loss: 0.0548 - val_accuracy: 0.9869 - 947ms/epoch - 3ms/step\n",
            "Epoch 5/700\n",
            "317/317 - 1s - loss: 0.0874 - accuracy: 0.9741 - val_loss: 0.0442 - val_accuracy: 0.9869 - 941ms/epoch - 3ms/step\n",
            "Epoch 6/700\n",
            "317/317 - 1s - loss: 0.0869 - accuracy: 0.9736 - val_loss: 0.0440 - val_accuracy: 0.9850 - 939ms/epoch - 3ms/step\n",
            "Epoch 7/700\n",
            "317/317 - 1s - loss: 0.0852 - accuracy: 0.9738 - val_loss: 0.0389 - val_accuracy: 0.9906 - 937ms/epoch - 3ms/step\n",
            "Epoch 8/700\n",
            "317/317 - 1s - loss: 0.0809 - accuracy: 0.9771 - val_loss: 0.0382 - val_accuracy: 0.9906 - 934ms/epoch - 3ms/step\n",
            "Epoch 9/700\n",
            "317/317 - 1s - loss: 0.0792 - accuracy: 0.9754 - val_loss: 0.0359 - val_accuracy: 0.9888 - 934ms/epoch - 3ms/step\n",
            "Epoch 10/700\n",
            "317/317 - 1s - loss: 0.0750 - accuracy: 0.9764 - val_loss: 0.0444 - val_accuracy: 0.9869 - 939ms/epoch - 3ms/step\n",
            "Epoch 11/700\n",
            "317/317 - 1s - loss: 0.0794 - accuracy: 0.9761 - val_loss: 0.0340 - val_accuracy: 0.9888 - 933ms/epoch - 3ms/step\n",
            "Epoch 12/700\n",
            "317/317 - 1s - loss: 0.0729 - accuracy: 0.9774 - val_loss: 0.0340 - val_accuracy: 0.9888 - 935ms/epoch - 3ms/step\n",
            "Epoch 13/700\n",
            "317/317 - 1s - loss: 0.0717 - accuracy: 0.9785 - val_loss: 0.0340 - val_accuracy: 0.9906 - 942ms/epoch - 3ms/step\n",
            "Epoch 14/700\n",
            "317/317 - 1s - loss: 0.0722 - accuracy: 0.9786 - val_loss: 0.0458 - val_accuracy: 0.9869 - 941ms/epoch - 3ms/step\n",
            "Epoch 15/700\n",
            "317/317 - 1s - loss: 0.0737 - accuracy: 0.9784 - val_loss: 0.0311 - val_accuracy: 0.9925 - 936ms/epoch - 3ms/step\n",
            "Epoch 16/700\n",
            "317/317 - 1s - loss: 0.0685 - accuracy: 0.9796 - val_loss: 0.0288 - val_accuracy: 0.9925 - 945ms/epoch - 3ms/step\n",
            "Epoch 17/700\n",
            "317/317 - 1s - loss: 0.0687 - accuracy: 0.9790 - val_loss: 0.0413 - val_accuracy: 0.9888 - 927ms/epoch - 3ms/step\n",
            "Epoch 18/700\n",
            "317/317 - 1s - loss: 0.0683 - accuracy: 0.9799 - val_loss: 0.0312 - val_accuracy: 0.9869 - 925ms/epoch - 3ms/step\n",
            "Epoch 19/700\n",
            "317/317 - 1s - loss: 0.0674 - accuracy: 0.9795 - val_loss: 0.0294 - val_accuracy: 0.9869 - 948ms/epoch - 3ms/step\n",
            "Epoch 20/700\n",
            "317/317 - 1s - loss: 0.0678 - accuracy: 0.9798 - val_loss: 0.0236 - val_accuracy: 0.9925 - 941ms/epoch - 3ms/step\n",
            "Epoch 21/700\n",
            "317/317 - 1s - loss: 0.0635 - accuracy: 0.9824 - val_loss: 0.0231 - val_accuracy: 0.9944 - 926ms/epoch - 3ms/step\n",
            "Epoch 22/700\n",
            "317/317 - 1s - loss: 0.0672 - accuracy: 0.9792 - val_loss: 0.0191 - val_accuracy: 0.9925 - 932ms/epoch - 3ms/step\n",
            "Epoch 23/700\n",
            "317/317 - 1s - loss: 0.0645 - accuracy: 0.9814 - val_loss: 0.0302 - val_accuracy: 0.9869 - 955ms/epoch - 3ms/step\n",
            "Epoch 24/700\n",
            "317/317 - 1s - loss: 0.0650 - accuracy: 0.9806 - val_loss: 0.0178 - val_accuracy: 0.9944 - 947ms/epoch - 3ms/step\n",
            "Epoch 25/700\n",
            "317/317 - 1s - loss: 0.0638 - accuracy: 0.9810 - val_loss: 0.0237 - val_accuracy: 0.9925 - 937ms/epoch - 3ms/step\n",
            "Epoch 26/700\n",
            "317/317 - 1s - loss: 0.0619 - accuracy: 0.9818 - val_loss: 0.0597 - val_accuracy: 0.9831 - 936ms/epoch - 3ms/step\n",
            "Epoch 27/700\n",
            "317/317 - 1s - loss: 0.0638 - accuracy: 0.9808 - val_loss: 0.0212 - val_accuracy: 0.9944 - 932ms/epoch - 3ms/step\n",
            "Epoch 28/700\n",
            "317/317 - 1s - loss: 0.0612 - accuracy: 0.9810 - val_loss: 0.0156 - val_accuracy: 0.9944 - 945ms/epoch - 3ms/step\n",
            "Epoch 29/700\n",
            "317/317 - 1s - loss: 0.0611 - accuracy: 0.9815 - val_loss: 0.0249 - val_accuracy: 0.9925 - 940ms/epoch - 3ms/step\n",
            "Epoch 30/700\n",
            "317/317 - 1s - loss: 0.0615 - accuracy: 0.9816 - val_loss: 0.0226 - val_accuracy: 0.9888 - 933ms/epoch - 3ms/step\n",
            "Epoch 31/700\n",
            "317/317 - 1s - loss: 0.0597 - accuracy: 0.9820 - val_loss: 0.0212 - val_accuracy: 0.9944 - 937ms/epoch - 3ms/step\n",
            "Epoch 32/700\n",
            "317/317 - 1s - loss: 0.0596 - accuracy: 0.9816 - val_loss: 0.0169 - val_accuracy: 0.9944 - 951ms/epoch - 3ms/step\n",
            "Epoch 33/700\n",
            "317/317 - 1s - loss: 0.0566 - accuracy: 0.9829 - val_loss: 0.0178 - val_accuracy: 0.9944 - 953ms/epoch - 3ms/step\n",
            "Epoch 34/700\n",
            "317/317 - 1s - loss: 0.0598 - accuracy: 0.9825 - val_loss: 0.0228 - val_accuracy: 0.9925 - 907ms/epoch - 3ms/step\n",
            "Epoch 35/700\n",
            "317/317 - 1s - loss: 0.0578 - accuracy: 0.9819 - val_loss: 0.0301 - val_accuracy: 0.9906 - 900ms/epoch - 3ms/step\n",
            "Epoch 36/700\n",
            "317/317 - 1s - loss: 0.0578 - accuracy: 0.9839 - val_loss: 0.0378 - val_accuracy: 0.9906 - 912ms/epoch - 3ms/step\n",
            "Epoch 37/700\n",
            "317/317 - 1s - loss: 0.0588 - accuracy: 0.9824 - val_loss: 0.0247 - val_accuracy: 0.9888 - 916ms/epoch - 3ms/step\n",
            "Epoch 38/700\n",
            "317/317 - 1s - loss: 0.0562 - accuracy: 0.9821 - val_loss: 0.0181 - val_accuracy: 0.9981 - 931ms/epoch - 3ms/step\n",
            "Epoch 39/700\n",
            "317/317 - 1s - loss: 0.0515 - accuracy: 0.9848 - val_loss: 0.0247 - val_accuracy: 0.9925 - 931ms/epoch - 3ms/step\n",
            "Epoch 40/700\n",
            "317/317 - 1s - loss: 0.0546 - accuracy: 0.9833 - val_loss: 0.0190 - val_accuracy: 0.9944 - 923ms/epoch - 3ms/step\n",
            "Epoch 41/700\n",
            "317/317 - 1s - loss: 0.0551 - accuracy: 0.9842 - val_loss: 0.0255 - val_accuracy: 0.9888 - 914ms/epoch - 3ms/step\n",
            "Epoch 42/700\n",
            "317/317 - 1s - loss: 0.0549 - accuracy: 0.9842 - val_loss: 0.0179 - val_accuracy: 0.9925 - 909ms/epoch - 3ms/step\n",
            "Epoch 43/700\n",
            "317/317 - 1s - loss: 0.0525 - accuracy: 0.9836 - val_loss: 0.0220 - val_accuracy: 0.9925 - 916ms/epoch - 3ms/step\n",
            "Epoch 44/700\n",
            "317/317 - 1s - loss: 0.0533 - accuracy: 0.9826 - val_loss: 0.0144 - val_accuracy: 0.9963 - 927ms/epoch - 3ms/step\n",
            "Epoch 45/700\n",
            "317/317 - 1s - loss: 0.0540 - accuracy: 0.9840 - val_loss: 0.0166 - val_accuracy: 0.9944 - 937ms/epoch - 3ms/step\n",
            "Epoch 46/700\n",
            "317/317 - 1s - loss: 0.0519 - accuracy: 0.9850 - val_loss: 0.0144 - val_accuracy: 0.9944 - 912ms/epoch - 3ms/step\n",
            "Epoch 47/700\n",
            "317/317 - 1s - loss: 0.0502 - accuracy: 0.9845 - val_loss: 0.0175 - val_accuracy: 0.9944 - 1s/epoch - 3ms/step\n",
            "Epoch 48/700\n",
            "317/317 - 1s - loss: 0.0488 - accuracy: 0.9843 - val_loss: 0.0157 - val_accuracy: 0.9963 - 1s/epoch - 4ms/step\n",
            "Epoch 49/700\n",
            "317/317 - 1s - loss: 0.0498 - accuracy: 0.9850 - val_loss: 0.0444 - val_accuracy: 0.9831 - 1s/epoch - 3ms/step\n",
            "Epoch 50/700\n",
            "317/317 - 1s - loss: 0.0497 - accuracy: 0.9842 - val_loss: 0.0525 - val_accuracy: 0.9850 - 962ms/epoch - 3ms/step\n",
            "Epoch 51/700\n",
            "317/317 - 1s - loss: 0.0499 - accuracy: 0.9851 - val_loss: 0.0201 - val_accuracy: 0.9944 - 909ms/epoch - 3ms/step\n",
            "Epoch 52/700\n",
            "317/317 - 1s - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.0196 - val_accuracy: 0.9944 - 911ms/epoch - 3ms/step\n",
            "Epoch 53/700\n",
            "317/317 - 1s - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.0147 - val_accuracy: 0.9944 - 929ms/epoch - 3ms/step\n",
            "Epoch 54/700\n",
            "317/317 - 1s - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.0130 - val_accuracy: 0.9944 - 916ms/epoch - 3ms/step\n",
            "Epoch 55/700\n",
            "317/317 - 1s - loss: 0.0463 - accuracy: 0.9858 - val_loss: 0.0131 - val_accuracy: 0.9963 - 968ms/epoch - 3ms/step\n",
            "Epoch 56/700\n",
            "317/317 - 1s - loss: 0.0492 - accuracy: 0.9848 - val_loss: 0.0168 - val_accuracy: 0.9944 - 944ms/epoch - 3ms/step\n",
            "Epoch 57/700\n",
            "317/317 - 1s - loss: 0.0487 - accuracy: 0.9846 - val_loss: 0.0213 - val_accuracy: 0.9906 - 927ms/epoch - 3ms/step\n",
            "Epoch 58/700\n",
            "317/317 - 1s - loss: 0.0448 - accuracy: 0.9860 - val_loss: 0.0160 - val_accuracy: 0.9981 - 925ms/epoch - 3ms/step\n",
            "Epoch 59/700\n",
            "317/317 - 1s - loss: 0.0451 - accuracy: 0.9849 - val_loss: 0.0164 - val_accuracy: 0.9963 - 926ms/epoch - 3ms/step\n",
            "Epoch 60/700\n",
            "317/317 - 1s - loss: 0.0448 - accuracy: 0.9852 - val_loss: 0.0169 - val_accuracy: 0.9925 - 926ms/epoch - 3ms/step\n",
            "Epoch 61/700\n",
            "317/317 - 1s - loss: 0.0454 - accuracy: 0.9844 - val_loss: 0.0167 - val_accuracy: 0.9963 - 935ms/epoch - 3ms/step\n",
            "Epoch 62/700\n",
            "317/317 - 1s - loss: 0.0414 - accuracy: 0.9869 - val_loss: 0.0166 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 63/700\n",
            "317/317 - 1s - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.0117 - val_accuracy: 0.9981 - 918ms/epoch - 3ms/step\n",
            "Epoch 64/700\n",
            "317/317 - 1s - loss: 0.0453 - accuracy: 0.9849 - val_loss: 0.0128 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 65/700\n",
            "317/317 - 1s - loss: 0.0466 - accuracy: 0.9841 - val_loss: 0.0138 - val_accuracy: 0.9963 - 932ms/epoch - 3ms/step\n",
            "Epoch 66/700\n",
            "317/317 - 1s - loss: 0.0427 - accuracy: 0.9864 - val_loss: 0.0099 - val_accuracy: 0.9963 - 938ms/epoch - 3ms/step\n",
            "Epoch 67/700\n",
            "317/317 - 1s - loss: 0.0437 - accuracy: 0.9861 - val_loss: 0.0153 - val_accuracy: 1.0000 - 933ms/epoch - 3ms/step\n",
            "Epoch 68/700\n",
            "317/317 - 1s - loss: 0.0436 - accuracy: 0.9856 - val_loss: 0.0564 - val_accuracy: 0.9850 - 935ms/epoch - 3ms/step\n",
            "Epoch 69/700\n",
            "317/317 - 1s - loss: 0.0430 - accuracy: 0.9852 - val_loss: 0.0120 - val_accuracy: 1.0000 - 930ms/epoch - 3ms/step\n",
            "Epoch 70/700\n",
            "317/317 - 1s - loss: 0.0442 - accuracy: 0.9849 - val_loss: 0.0148 - val_accuracy: 0.9963 - 940ms/epoch - 3ms/step\n",
            "Epoch 71/700\n",
            "317/317 - 1s - loss: 0.0431 - accuracy: 0.9842 - val_loss: 0.0152 - val_accuracy: 0.9944 - 940ms/epoch - 3ms/step\n",
            "Epoch 72/700\n",
            "317/317 - 1s - loss: 0.0404 - accuracy: 0.9866 - val_loss: 0.0261 - val_accuracy: 0.9888 - 928ms/epoch - 3ms/step\n",
            "Epoch 73/700\n",
            "317/317 - 1s - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.0307 - val_accuracy: 0.9869 - 929ms/epoch - 3ms/step\n",
            "Epoch 74/700\n",
            "317/317 - 1s - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.0217 - val_accuracy: 0.9944 - 935ms/epoch - 3ms/step\n",
            "Epoch 75/700\n",
            "317/317 - 1s - loss: 0.0417 - accuracy: 0.9849 - val_loss: 0.0125 - val_accuracy: 0.9963 - 944ms/epoch - 3ms/step\n",
            "Epoch 76/700\n",
            "317/317 - 1s - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.0122 - val_accuracy: 0.9963 - 935ms/epoch - 3ms/step\n",
            "Epoch 77/700\n",
            "317/317 - 1s - loss: 0.0400 - accuracy: 0.9871 - val_loss: 0.0148 - val_accuracy: 0.9963 - 931ms/epoch - 3ms/step\n",
            "Epoch 78/700\n",
            "317/317 - 1s - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0130 - val_accuracy: 0.9963 - 947ms/epoch - 3ms/step\n",
            "Epoch 79/700\n",
            "317/317 - 1s - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.0208 - val_accuracy: 0.9925 - 939ms/epoch - 3ms/step\n",
            "Epoch 80/700\n",
            "317/317 - 1s - loss: 0.0373 - accuracy: 0.9874 - val_loss: 0.0285 - val_accuracy: 0.9925 - 938ms/epoch - 3ms/step\n",
            "Epoch 81/700\n",
            "317/317 - 1s - loss: 0.0387 - accuracy: 0.9877 - val_loss: 0.0148 - val_accuracy: 0.9963 - 935ms/epoch - 3ms/step\n",
            "Epoch 82/700\n",
            "317/317 - 1s - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.0229 - val_accuracy: 0.9944 - 917ms/epoch - 3ms/step\n",
            "Epoch 83/700\n",
            "317/317 - 1s - loss: 0.0375 - accuracy: 0.9880 - val_loss: 0.0228 - val_accuracy: 0.9944 - 936ms/epoch - 3ms/step\n",
            "Epoch 84/700\n",
            "317/317 - 1s - loss: 0.0399 - accuracy: 0.9862 - val_loss: 0.0257 - val_accuracy: 0.9925 - 930ms/epoch - 3ms/step\n",
            "Epoch 85/700\n",
            "317/317 - 1s - loss: 0.0375 - accuracy: 0.9878 - val_loss: 0.0211 - val_accuracy: 0.9925 - 932ms/epoch - 3ms/step\n",
            "Epoch 86/700\n",
            "317/317 - 1s - loss: 0.0344 - accuracy: 0.9886 - val_loss: 0.0245 - val_accuracy: 0.9925 - 934ms/epoch - 3ms/step\n",
            "Epoch 87/700\n",
            "317/317 - 1s - loss: 0.0406 - accuracy: 0.9866 - val_loss: 0.0169 - val_accuracy: 0.9963 - 952ms/epoch - 3ms/step\n",
            "Epoch 88/700\n",
            "317/317 - 1s - loss: 0.0342 - accuracy: 0.9887 - val_loss: 0.0174 - val_accuracy: 0.9925 - 969ms/epoch - 3ms/step\n",
            "Epoch 89/700\n",
            "317/317 - 1s - loss: 0.0357 - accuracy: 0.9874 - val_loss: 0.0176 - val_accuracy: 0.9944 - 958ms/epoch - 3ms/step\n",
            "Epoch 90/700\n",
            "317/317 - 1s - loss: 0.0352 - accuracy: 0.9887 - val_loss: 0.0262 - val_accuracy: 0.9925 - 931ms/epoch - 3ms/step\n",
            "Epoch 91/700\n",
            "317/317 - 1s - loss: 0.0354 - accuracy: 0.9865 - val_loss: 0.0134 - val_accuracy: 0.9944 - 934ms/epoch - 3ms/step\n",
            "Epoch 92/700\n",
            "317/317 - 1s - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.0157 - val_accuracy: 0.9963 - 946ms/epoch - 3ms/step\n",
            "Epoch 93/700\n",
            "317/317 - 1s - loss: 0.0359 - accuracy: 0.9875 - val_loss: 0.0160 - val_accuracy: 0.9963 - 933ms/epoch - 3ms/step\n",
            "Epoch 94/700\n",
            "317/317 - 1s - loss: 0.0328 - accuracy: 0.9878 - val_loss: 0.0227 - val_accuracy: 0.9925 - 931ms/epoch - 3ms/step\n",
            "Epoch 95/700\n",
            "317/317 - 1s - loss: 0.0349 - accuracy: 0.9878 - val_loss: 0.0251 - val_accuracy: 0.9888 - 949ms/epoch - 3ms/step\n",
            "Epoch 96/700\n",
            "317/317 - 1s - loss: 0.0332 - accuracy: 0.9888 - val_loss: 0.0256 - val_accuracy: 0.9906 - 931ms/epoch - 3ms/step\n",
            "Epoch 97/700\n",
            "317/317 - 1s - loss: 0.0335 - accuracy: 0.9877 - val_loss: 0.0141 - val_accuracy: 0.9963 - 947ms/epoch - 3ms/step\n",
            "Epoch 98/700\n",
            "317/317 - 1s - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.0119 - val_accuracy: 0.9944 - 934ms/epoch - 3ms/step\n",
            "Epoch 99/700\n",
            "317/317 - 1s - loss: 0.0332 - accuracy: 0.9887 - val_loss: 0.0239 - val_accuracy: 0.9888 - 933ms/epoch - 3ms/step\n",
            "Epoch 100/700\n",
            "317/317 - 1s - loss: 0.0336 - accuracy: 0.9879 - val_loss: 0.0232 - val_accuracy: 0.9906 - 947ms/epoch - 3ms/step\n",
            "Epoch 101/700\n",
            "317/317 - 1s - loss: 0.0318 - accuracy: 0.9897 - val_loss: 0.0094 - val_accuracy: 0.9981 - 948ms/epoch - 3ms/step\n",
            "Epoch 102/700\n",
            "317/317 - 1s - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.0221 - val_accuracy: 0.9925 - 964ms/epoch - 3ms/step\n",
            "Epoch 103/700\n",
            "317/317 - 1s - loss: 0.0325 - accuracy: 0.9877 - val_loss: 0.0158 - val_accuracy: 0.9963 - 945ms/epoch - 3ms/step\n",
            "Epoch 104/700\n",
            "317/317 - 1s - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.0207 - val_accuracy: 0.9906 - 928ms/epoch - 3ms/step\n",
            "Epoch 105/700\n",
            "317/317 - 1s - loss: 0.0308 - accuracy: 0.9886 - val_loss: 0.0255 - val_accuracy: 0.9906 - 935ms/epoch - 3ms/step\n",
            "Epoch 106/700\n",
            "317/317 - 1s - loss: 0.0317 - accuracy: 0.9886 - val_loss: 0.0316 - val_accuracy: 0.9888 - 957ms/epoch - 3ms/step\n",
            "Epoch 107/700\n",
            "317/317 - 1s - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0378 - val_accuracy: 0.9869 - 980ms/epoch - 3ms/step\n",
            "Epoch 108/700\n",
            "317/317 - 1s - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.0096 - val_accuracy: 0.9981 - 975ms/epoch - 3ms/step\n",
            "Epoch 109/700\n",
            "317/317 - 1s - loss: 0.0315 - accuracy: 0.9890 - val_loss: 0.0164 - val_accuracy: 0.9944 - 950ms/epoch - 3ms/step\n",
            "Epoch 110/700\n",
            "317/317 - 1s - loss: 0.0310 - accuracy: 0.9895 - val_loss: 0.0145 - val_accuracy: 0.9944 - 919ms/epoch - 3ms/step\n",
            "Epoch 111/700\n",
            "317/317 - 1s - loss: 0.0312 - accuracy: 0.9883 - val_loss: 0.0151 - val_accuracy: 0.9925 - 956ms/epoch - 3ms/step\n",
            "Epoch 112/700\n",
            "317/317 - 1s - loss: 0.0344 - accuracy: 0.9881 - val_loss: 0.0253 - val_accuracy: 0.9963 - 932ms/epoch - 3ms/step\n",
            "Epoch 113/700\n",
            "317/317 - 1s - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.0246 - val_accuracy: 0.9906 - 914ms/epoch - 3ms/step\n",
            "Epoch 114/700\n",
            "317/317 - 1s - loss: 0.0299 - accuracy: 0.9889 - val_loss: 0.0114 - val_accuracy: 0.9963 - 895ms/epoch - 3ms/step\n",
            "Epoch 115/700\n",
            "317/317 - 1s - loss: 0.0288 - accuracy: 0.9893 - val_loss: 0.0229 - val_accuracy: 0.9925 - 909ms/epoch - 3ms/step\n",
            "Epoch 116/700\n",
            "317/317 - 1s - loss: 0.0290 - accuracy: 0.9891 - val_loss: 0.0287 - val_accuracy: 0.9888 - 900ms/epoch - 3ms/step\n",
            "Epoch 117/700\n",
            "317/317 - 1s - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.0172 - val_accuracy: 0.9944 - 913ms/epoch - 3ms/step\n",
            "Epoch 118/700\n",
            "317/317 - 1s - loss: 0.0269 - accuracy: 0.9899 - val_loss: 0.0232 - val_accuracy: 0.9906 - 927ms/epoch - 3ms/step\n",
            "Epoch 119/700\n",
            "317/317 - 1s - loss: 0.0316 - accuracy: 0.9882 - val_loss: 0.0198 - val_accuracy: 0.9906 - 917ms/epoch - 3ms/step\n",
            "Epoch 120/700\n",
            "317/317 - 1s - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.0183 - val_accuracy: 0.9925 - 937ms/epoch - 3ms/step\n",
            "Epoch 121/700\n",
            "317/317 - 1s - loss: 0.0281 - accuracy: 0.9896 - val_loss: 0.0198 - val_accuracy: 0.9944 - 904ms/epoch - 3ms/step\n",
            "Epoch 122/700\n",
            "317/317 - 1s - loss: 0.0277 - accuracy: 0.9897 - val_loss: 0.0197 - val_accuracy: 0.9944 - 898ms/epoch - 3ms/step\n",
            "Epoch 123/700\n",
            "317/317 - 1s - loss: 0.0306 - accuracy: 0.9894 - val_loss: 0.0173 - val_accuracy: 0.9963 - 929ms/epoch - 3ms/step\n",
            "Epoch 124/700\n",
            "317/317 - 1s - loss: 0.0281 - accuracy: 0.9896 - val_loss: 0.0503 - val_accuracy: 0.9850 - 928ms/epoch - 3ms/step\n",
            "Epoch 125/700\n",
            "317/317 - 1s - loss: 0.0312 - accuracy: 0.9887 - val_loss: 0.0160 - val_accuracy: 0.9963 - 911ms/epoch - 3ms/step\n",
            "Epoch 126/700\n",
            "317/317 - 1s - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.0227 - val_accuracy: 0.9906 - 911ms/epoch - 3ms/step\n",
            "Epoch 127/700\n",
            "317/317 - 1s - loss: 0.0271 - accuracy: 0.9899 - val_loss: 0.0249 - val_accuracy: 0.9925 - 930ms/epoch - 3ms/step\n",
            "Epoch 128/700\n",
            "317/317 - 1s - loss: 0.0302 - accuracy: 0.9891 - val_loss: 0.0120 - val_accuracy: 0.9944 - 932ms/epoch - 3ms/step\n",
            "Epoch 129/700\n",
            "317/317 - 1s - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.0100 - val_accuracy: 0.9981 - 919ms/epoch - 3ms/step\n",
            "Epoch 130/700\n",
            "317/317 - 1s - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.0119 - val_accuracy: 0.9963 - 935ms/epoch - 3ms/step\n",
            "Epoch 131/700\n",
            "317/317 - 1s - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.0171 - val_accuracy: 0.9944 - 955ms/epoch - 3ms/step\n",
            "Epoch 132/700\n",
            "317/317 - 1s - loss: 0.0285 - accuracy: 0.9902 - val_loss: 0.0147 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 133/700\n",
            "317/317 - 1s - loss: 0.0257 - accuracy: 0.9905 - val_loss: 0.0134 - val_accuracy: 0.9906 - 921ms/epoch - 3ms/step\n",
            "Epoch 134/700\n",
            "317/317 - 1s - loss: 0.0264 - accuracy: 0.9907 - val_loss: 0.0100 - val_accuracy: 0.9981 - 933ms/epoch - 3ms/step\n",
            "Epoch 135/700\n",
            "317/317 - 1s - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.0118 - val_accuracy: 0.9963 - 947ms/epoch - 3ms/step\n",
            "Epoch 136/700\n",
            "317/317 - 1s - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.0125 - val_accuracy: 0.9963 - 928ms/epoch - 3ms/step\n",
            "Epoch 137/700\n",
            "317/317 - 1s - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0129 - val_accuracy: 0.9981 - 936ms/epoch - 3ms/step\n",
            "Epoch 138/700\n",
            "317/317 - 1s - loss: 0.0242 - accuracy: 0.9911 - val_loss: 0.0148 - val_accuracy: 0.9925 - 922ms/epoch - 3ms/step\n",
            "Epoch 139/700\n",
            "317/317 - 1s - loss: 0.0245 - accuracy: 0.9910 - val_loss: 0.0170 - val_accuracy: 0.9925 - 940ms/epoch - 3ms/step\n",
            "Epoch 140/700\n",
            "317/317 - 1s - loss: 0.0276 - accuracy: 0.9896 - val_loss: 0.0200 - val_accuracy: 0.9944 - 932ms/epoch - 3ms/step\n",
            "Epoch 141/700\n",
            "317/317 - 1s - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.0128 - val_accuracy: 0.9944 - 940ms/epoch - 3ms/step\n",
            "Epoch 142/700\n",
            "317/317 - 1s - loss: 0.0257 - accuracy: 0.9906 - val_loss: 0.0202 - val_accuracy: 0.9906 - 936ms/epoch - 3ms/step\n",
            "Epoch 143/700\n",
            "317/317 - 1s - loss: 0.0241 - accuracy: 0.9906 - val_loss: 0.0105 - val_accuracy: 0.9981 - 937ms/epoch - 3ms/step\n",
            "Epoch 144/700\n",
            "317/317 - 1s - loss: 0.0250 - accuracy: 0.9903 - val_loss: 0.0259 - val_accuracy: 0.9888 - 936ms/epoch - 3ms/step\n",
            "Epoch 145/700\n",
            "317/317 - 1s - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.0152 - val_accuracy: 0.9963 - 929ms/epoch - 3ms/step\n",
            "Epoch 146/700\n",
            "317/317 - 1s - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.0108 - val_accuracy: 0.9944 - 933ms/epoch - 3ms/step\n",
            "Epoch 147/700\n",
            "317/317 - 1s - loss: 0.0242 - accuracy: 0.9914 - val_loss: 0.0356 - val_accuracy: 0.9831 - 932ms/epoch - 3ms/step\n",
            "Epoch 148/700\n",
            "317/317 - 1s - loss: 0.0275 - accuracy: 0.9898 - val_loss: 0.0228 - val_accuracy: 0.9925 - 919ms/epoch - 3ms/step\n",
            "Epoch 149/700\n",
            "317/317 - 1s - loss: 0.0222 - accuracy: 0.9913 - val_loss: 0.0132 - val_accuracy: 0.9944 - 941ms/epoch - 3ms/step\n",
            "Epoch 150/700\n",
            "317/317 - 1s - loss: 0.0237 - accuracy: 0.9912 - val_loss: 0.0102 - val_accuracy: 0.9963 - 928ms/epoch - 3ms/step\n",
            "Epoch 151/700\n",
            "317/317 - 1s - loss: 0.0285 - accuracy: 0.9894 - val_loss: 0.0196 - val_accuracy: 0.9906 - 930ms/epoch - 3ms/step\n",
            "Epoch 152/700\n",
            "317/317 - 1s - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.0167 - val_accuracy: 0.9925 - 974ms/epoch - 3ms/step\n",
            "Epoch 153/700\n",
            "317/317 - 1s - loss: 0.0252 - accuracy: 0.9903 - val_loss: 0.0124 - val_accuracy: 0.9944 - 938ms/epoch - 3ms/step\n",
            "Epoch 154/700\n",
            "317/317 - 1s - loss: 0.0248 - accuracy: 0.9910 - val_loss: 0.0087 - val_accuracy: 0.9963 - 934ms/epoch - 3ms/step\n",
            "Epoch 155/700\n",
            "317/317 - 1s - loss: 0.0231 - accuracy: 0.9918 - val_loss: 0.0190 - val_accuracy: 0.9944 - 940ms/epoch - 3ms/step\n",
            "Epoch 156/700\n",
            "317/317 - 1s - loss: 0.0220 - accuracy: 0.9911 - val_loss: 0.0110 - val_accuracy: 0.9963 - 934ms/epoch - 3ms/step\n",
            "Epoch 157/700\n",
            "317/317 - 1s - loss: 0.0279 - accuracy: 0.9895 - val_loss: 0.0153 - val_accuracy: 0.9944 - 940ms/epoch - 3ms/step\n",
            "Epoch 158/700\n",
            "317/317 - 1s - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.0230 - val_accuracy: 0.9906 - 938ms/epoch - 3ms/step\n",
            "Epoch 159/700\n",
            "317/317 - 1s - loss: 0.0244 - accuracy: 0.9912 - val_loss: 0.0096 - val_accuracy: 0.9981 - 934ms/epoch - 3ms/step\n",
            "Epoch 160/700\n",
            "317/317 - 1s - loss: 0.0244 - accuracy: 0.9912 - val_loss: 0.0113 - val_accuracy: 0.9944 - 940ms/epoch - 3ms/step\n",
            "Epoch 161/700\n",
            "317/317 - 1s - loss: 0.0234 - accuracy: 0.9914 - val_loss: 0.0163 - val_accuracy: 0.9925 - 918ms/epoch - 3ms/step\n",
            "Epoch 162/700\n",
            "317/317 - 1s - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.0176 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 163/700\n",
            "317/317 - 1s - loss: 0.0222 - accuracy: 0.9920 - val_loss: 0.0096 - val_accuracy: 0.9944 - 939ms/epoch - 3ms/step\n",
            "Epoch 164/700\n",
            "317/317 - 1s - loss: 0.0205 - accuracy: 0.9920 - val_loss: 0.0128 - val_accuracy: 0.9944 - 932ms/epoch - 3ms/step\n",
            "Epoch 165/700\n",
            "317/317 - 1s - loss: 0.0231 - accuracy: 0.9916 - val_loss: 0.0165 - val_accuracy: 0.9944 - 934ms/epoch - 3ms/step\n",
            "Epoch 166/700\n",
            "317/317 - 1s - loss: 0.0239 - accuracy: 0.9898 - val_loss: 0.0125 - val_accuracy: 0.9944 - 938ms/epoch - 3ms/step\n",
            "Epoch 167/700\n",
            "317/317 - 1s - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0116 - val_accuracy: 0.9925 - 939ms/epoch - 3ms/step\n",
            "Epoch 168/700\n",
            "317/317 - 1s - loss: 0.0210 - accuracy: 0.9917 - val_loss: 0.0067 - val_accuracy: 0.9963 - 948ms/epoch - 3ms/step\n",
            "Epoch 169/700\n",
            "317/317 - 1s - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.0121 - val_accuracy: 0.9963 - 936ms/epoch - 3ms/step\n",
            "Epoch 170/700\n",
            "317/317 - 1s - loss: 0.0216 - accuracy: 0.9919 - val_loss: 0.0147 - val_accuracy: 0.9944 - 934ms/epoch - 3ms/step\n",
            "Epoch 171/700\n",
            "317/317 - 1s - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.0106 - val_accuracy: 0.9963 - 937ms/epoch - 3ms/step\n",
            "Epoch 172/700\n",
            "317/317 - 1s - loss: 0.0218 - accuracy: 0.9914 - val_loss: 0.0417 - val_accuracy: 0.9813 - 931ms/epoch - 3ms/step\n",
            "Epoch 173/700\n",
            "317/317 - 1s - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.0118 - val_accuracy: 0.9944 - 939ms/epoch - 3ms/step\n",
            "Epoch 174/700\n",
            "317/317 - 1s - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.0084 - val_accuracy: 0.9981 - 965ms/epoch - 3ms/step\n",
            "Epoch 175/700\n",
            "317/317 - 1s - loss: 0.0189 - accuracy: 0.9924 - val_loss: 0.0168 - val_accuracy: 0.9944 - 936ms/epoch - 3ms/step\n",
            "Epoch 176/700\n",
            "317/317 - 1s - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.0360 - val_accuracy: 0.9888 - 935ms/epoch - 3ms/step\n",
            "Epoch 177/700\n",
            "317/317 - 1s - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0085 - val_accuracy: 0.9963 - 914ms/epoch - 3ms/step\n",
            "Epoch 178/700\n",
            "317/317 - 1s - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.0232 - val_accuracy: 0.9944 - 925ms/epoch - 3ms/step\n",
            "Epoch 179/700\n",
            "317/317 - 1s - loss: 0.0204 - accuracy: 0.9925 - val_loss: 0.0181 - val_accuracy: 0.9944 - 942ms/epoch - 3ms/step\n",
            "Epoch 180/700\n",
            "317/317 - 1s - loss: 0.0212 - accuracy: 0.9925 - val_loss: 0.0281 - val_accuracy: 0.9925 - 924ms/epoch - 3ms/step\n",
            "Epoch 181/700\n",
            "317/317 - 1s - loss: 0.0175 - accuracy: 0.9934 - val_loss: 0.0112 - val_accuracy: 0.9981 - 940ms/epoch - 3ms/step\n",
            "Epoch 182/700\n",
            "317/317 - 1s - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.0076 - val_accuracy: 0.9963 - 946ms/epoch - 3ms/step\n",
            "Epoch 183/700\n",
            "317/317 - 1s - loss: 0.0173 - accuracy: 0.9930 - val_loss: 0.0166 - val_accuracy: 0.9925 - 938ms/epoch - 3ms/step\n",
            "Epoch 184/700\n",
            "317/317 - 1s - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0121 - val_accuracy: 0.9963 - 939ms/epoch - 3ms/step\n",
            "Epoch 185/700\n",
            "317/317 - 1s - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.0203 - val_accuracy: 0.9944 - 955ms/epoch - 3ms/step\n",
            "Epoch 186/700\n",
            "317/317 - 1s - loss: 0.0216 - accuracy: 0.9918 - val_loss: 0.0112 - val_accuracy: 0.9963 - 942ms/epoch - 3ms/step\n",
            "Epoch 187/700\n",
            "317/317 - 1s - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.0126 - val_accuracy: 0.9944 - 929ms/epoch - 3ms/step\n",
            "Epoch 188/700\n",
            "317/317 - 1s - loss: 0.0196 - accuracy: 0.9920 - val_loss: 0.0091 - val_accuracy: 0.9963 - 933ms/epoch - 3ms/step\n",
            "Epoch 189/700\n",
            "317/317 - 1s - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.0111 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 190/700\n",
            "317/317 - 1s - loss: 0.0193 - accuracy: 0.9924 - val_loss: 0.0095 - val_accuracy: 0.9963 - 947ms/epoch - 3ms/step\n",
            "Epoch 191/700\n",
            "317/317 - 1s - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.0184 - val_accuracy: 0.9944 - 934ms/epoch - 3ms/step\n",
            "Epoch 192/700\n",
            "317/317 - 1s - loss: 0.0195 - accuracy: 0.9928 - val_loss: 0.0179 - val_accuracy: 0.9944 - 928ms/epoch - 3ms/step\n",
            "Epoch 193/700\n",
            "317/317 - 1s - loss: 0.0209 - accuracy: 0.9918 - val_loss: 0.0136 - val_accuracy: 0.9906 - 921ms/epoch - 3ms/step\n",
            "Epoch 194/700\n",
            "317/317 - 1s - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0077 - val_accuracy: 0.9981 - 933ms/epoch - 3ms/step\n",
            "Epoch 195/700\n",
            "317/317 - 1s - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0133 - val_accuracy: 0.9981 - 933ms/epoch - 3ms/step\n",
            "Epoch 196/700\n",
            "317/317 - 1s - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0146 - val_accuracy: 0.9925 - 918ms/epoch - 3ms/step\n",
            "Epoch 197/700\n",
            "317/317 - 1s - loss: 0.0194 - accuracy: 0.9929 - val_loss: 0.0103 - val_accuracy: 0.9944 - 926ms/epoch - 3ms/step\n",
            "Epoch 198/700\n",
            "317/317 - 1s - loss: 0.0194 - accuracy: 0.9926 - val_loss: 0.0112 - val_accuracy: 0.9925 - 917ms/epoch - 3ms/step\n",
            "Epoch 199/700\n",
            "317/317 - 1s - loss: 0.0186 - accuracy: 0.9934 - val_loss: 0.0089 - val_accuracy: 0.9981 - 921ms/epoch - 3ms/step\n",
            "Epoch 200/700\n",
            "317/317 - 1s - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0123 - val_accuracy: 0.9944 - 905ms/epoch - 3ms/step\n",
            "Epoch 201/700\n",
            "317/317 - 1s - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0090 - val_accuracy: 0.9981 - 927ms/epoch - 3ms/step\n",
            "Epoch 202/700\n",
            "317/317 - 1s - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.0097 - val_accuracy: 0.9963 - 912ms/epoch - 3ms/step\n",
            "Epoch 203/700\n",
            "317/317 - 1s - loss: 0.0189 - accuracy: 0.9923 - val_loss: 0.0105 - val_accuracy: 0.9944 - 902ms/epoch - 3ms/step\n",
            "Epoch 204/700\n",
            "317/317 - 1s - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.0124 - val_accuracy: 0.9944 - 912ms/epoch - 3ms/step\n",
            "Epoch 205/700\n",
            "317/317 - 1s - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0173 - val_accuracy: 0.9944 - 903ms/epoch - 3ms/step\n",
            "Epoch 206/700\n",
            "317/317 - 1s - loss: 0.0185 - accuracy: 0.9929 - val_loss: 0.0096 - val_accuracy: 0.9963 - 920ms/epoch - 3ms/step\n",
            "Epoch 207/700\n",
            "317/317 - 1s - loss: 0.0199 - accuracy: 0.9926 - val_loss: 0.0151 - val_accuracy: 0.9925 - 912ms/epoch - 3ms/step\n",
            "Epoch 208/700\n",
            "317/317 - 1s - loss: 0.0194 - accuracy: 0.9929 - val_loss: 0.0143 - val_accuracy: 0.9981 - 904ms/epoch - 3ms/step\n",
            "Epoch 209/700\n",
            "317/317 - 1s - loss: 0.0215 - accuracy: 0.9920 - val_loss: 0.0144 - val_accuracy: 0.9963 - 939ms/epoch - 3ms/step\n",
            "Epoch 210/700\n",
            "317/317 - 1s - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.0153 - val_accuracy: 0.9944 - 910ms/epoch - 3ms/step\n",
            "Epoch 211/700\n",
            "317/317 - 1s - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0282 - val_accuracy: 0.9888 - 916ms/epoch - 3ms/step\n",
            "Epoch 212/700\n",
            "317/317 - 1s - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.0153 - val_accuracy: 0.9981 - 921ms/epoch - 3ms/step\n",
            "Epoch 213/700\n",
            "317/317 - 1s - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0183 - val_accuracy: 0.9925 - 924ms/epoch - 3ms/step\n",
            "Epoch 214/700\n",
            "317/317 - 1s - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.0156 - val_accuracy: 0.9944 - 926ms/epoch - 3ms/step\n",
            "Epoch 215/700\n",
            "317/317 - 1s - loss: 0.0172 - accuracy: 0.9936 - val_loss: 0.0062 - val_accuracy: 0.9981 - 923ms/epoch - 3ms/step\n",
            "Epoch 216/700\n",
            "317/317 - 1s - loss: 0.0161 - accuracy: 0.9941 - val_loss: 0.0158 - val_accuracy: 0.9944 - 922ms/epoch - 3ms/step\n",
            "Epoch 217/700\n",
            "317/317 - 1s - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0208 - val_accuracy: 0.9906 - 987ms/epoch - 3ms/step\n",
            "Epoch 218/700\n",
            "317/317 - 1s - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.0119 - val_accuracy: 0.9925 - 941ms/epoch - 3ms/step\n",
            "Epoch 219/700\n",
            "317/317 - 1s - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.0274 - val_accuracy: 0.9888 - 927ms/epoch - 3ms/step\n",
            "Epoch 220/700\n",
            "317/317 - 1s - loss: 0.0164 - accuracy: 0.9941 - val_loss: 0.0193 - val_accuracy: 0.9906 - 934ms/epoch - 3ms/step\n",
            "Epoch 221/700\n",
            "317/317 - 1s - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0171 - val_accuracy: 0.9925 - 919ms/epoch - 3ms/step\n",
            "Epoch 222/700\n",
            "317/317 - 1s - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.0152 - val_accuracy: 0.9944 - 937ms/epoch - 3ms/step\n",
            "Epoch 223/700\n",
            "317/317 - 1s - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0106 - val_accuracy: 0.9963 - 937ms/epoch - 3ms/step\n",
            "Epoch 224/700\n",
            "317/317 - 1s - loss: 0.0163 - accuracy: 0.9941 - val_loss: 0.0221 - val_accuracy: 0.9944 - 937ms/epoch - 3ms/step\n",
            "Epoch 225/700\n",
            "317/317 - 1s - loss: 0.0233 - accuracy: 0.9913 - val_loss: 0.0202 - val_accuracy: 0.9925 - 918ms/epoch - 3ms/step\n",
            "Epoch 226/700\n",
            "317/317 - 1s - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.0103 - val_accuracy: 0.9981 - 926ms/epoch - 3ms/step\n",
            "Epoch 227/700\n",
            "317/317 - 1s - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0212 - val_accuracy: 0.9925 - 917ms/epoch - 3ms/step\n",
            "Epoch 228/700\n",
            "317/317 - 1s - loss: 0.0164 - accuracy: 0.9935 - val_loss: 0.0188 - val_accuracy: 0.9925 - 928ms/epoch - 3ms/step\n",
            "Epoch 229/700\n",
            "317/317 - 1s - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.0126 - val_accuracy: 0.9963 - 942ms/epoch - 3ms/step\n",
            "Epoch 230/700\n",
            "317/317 - 1s - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.0100 - val_accuracy: 0.9963 - 920ms/epoch - 3ms/step\n",
            "Epoch 231/700\n",
            "317/317 - 1s - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.0173 - val_accuracy: 0.9925 - 936ms/epoch - 3ms/step\n",
            "Epoch 232/700\n",
            "317/317 - 1s - loss: 0.0136 - accuracy: 0.9943 - val_loss: 0.0140 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 233/700\n",
            "317/317 - 1s - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.0179 - val_accuracy: 0.9944 - 936ms/epoch - 3ms/step\n",
            "Epoch 234/700\n",
            "317/317 - 1s - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.0169 - val_accuracy: 0.9963 - 929ms/epoch - 3ms/step\n",
            "Epoch 235/700\n",
            "317/317 - 1s - loss: 0.0188 - accuracy: 0.9930 - val_loss: 0.0126 - val_accuracy: 0.9963 - 953ms/epoch - 3ms/step\n",
            "Epoch 236/700\n",
            "317/317 - 1s - loss: 0.0167 - accuracy: 0.9936 - val_loss: 0.0151 - val_accuracy: 0.9944 - 925ms/epoch - 3ms/step\n",
            "Epoch 237/700\n",
            "317/317 - 1s - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.0212 - val_accuracy: 0.9925 - 953ms/epoch - 3ms/step\n",
            "Epoch 238/700\n",
            "317/317 - 1s - loss: 0.0184 - accuracy: 0.9928 - val_loss: 0.0184 - val_accuracy: 0.9944 - 936ms/epoch - 3ms/step\n",
            "Epoch 239/700\n",
            "317/317 - 1s - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.0249 - val_accuracy: 0.9888 - 957ms/epoch - 3ms/step\n",
            "Epoch 240/700\n",
            "317/317 - 1s - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0076 - val_accuracy: 0.9981 - 951ms/epoch - 3ms/step\n",
            "Epoch 241/700\n",
            "317/317 - 1s - loss: 0.0136 - accuracy: 0.9944 - val_loss: 0.0074 - val_accuracy: 0.9963 - 926ms/epoch - 3ms/step\n",
            "Epoch 242/700\n",
            "317/317 - 1s - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.0147 - val_accuracy: 0.9963 - 936ms/epoch - 3ms/step\n",
            "Epoch 243/700\n",
            "317/317 - 1s - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.0213 - val_accuracy: 0.9906 - 918ms/epoch - 3ms/step\n",
            "Epoch 244/700\n",
            "317/317 - 1s - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.0100 - val_accuracy: 0.9963 - 931ms/epoch - 3ms/step\n",
            "Epoch 245/700\n",
            "317/317 - 1s - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.0101 - val_accuracy: 0.9944 - 923ms/epoch - 3ms/step\n",
            "Epoch 246/700\n",
            "317/317 - 1s - loss: 0.0133 - accuracy: 0.9946 - val_loss: 0.0256 - val_accuracy: 0.9944 - 933ms/epoch - 3ms/step\n",
            "Epoch 247/700\n",
            "317/317 - 1s - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.0170 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 248/700\n",
            "317/317 - 1s - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0094 - val_accuracy: 0.9963 - 923ms/epoch - 3ms/step\n",
            "Epoch 249/700\n",
            "317/317 - 1s - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.0136 - val_accuracy: 0.9944 - 934ms/epoch - 3ms/step\n",
            "Epoch 250/700\n",
            "317/317 - 1s - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0134 - val_accuracy: 0.9963 - 958ms/epoch - 3ms/step\n",
            "Epoch 251/700\n",
            "317/317 - 1s - loss: 0.0135 - accuracy: 0.9950 - val_loss: 0.0170 - val_accuracy: 0.9925 - 939ms/epoch - 3ms/step\n",
            "Epoch 252/700\n",
            "317/317 - 1s - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.0134 - val_accuracy: 0.9963 - 922ms/epoch - 3ms/step\n",
            "Epoch 253/700\n",
            "317/317 - 1s - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0346 - val_accuracy: 0.9944 - 935ms/epoch - 3ms/step\n",
            "Epoch 254/700\n",
            "317/317 - 1s - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.0213 - val_accuracy: 0.9925 - 927ms/epoch - 3ms/step\n",
            "Epoch 255/700\n",
            "317/317 - 1s - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.0110 - val_accuracy: 0.9944 - 924ms/epoch - 3ms/step\n",
            "Epoch 256/700\n",
            "317/317 - 1s - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.0094 - val_accuracy: 0.9963 - 943ms/epoch - 3ms/step\n",
            "Epoch 257/700\n",
            "317/317 - 1s - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0105 - val_accuracy: 0.9981 - 941ms/epoch - 3ms/step\n",
            "Epoch 258/700\n",
            "317/317 - 1s - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.0114 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 259/700\n",
            "317/317 - 1s - loss: 0.0161 - accuracy: 0.9926 - val_loss: 0.0187 - val_accuracy: 0.9925 - 921ms/epoch - 3ms/step\n",
            "Epoch 260/700\n",
            "317/317 - 1s - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0096 - val_accuracy: 0.9963 - 936ms/epoch - 3ms/step\n",
            "Epoch 261/700\n",
            "317/317 - 1s - loss: 0.0158 - accuracy: 0.9939 - val_loss: 0.0141 - val_accuracy: 0.9944 - 922ms/epoch - 3ms/step\n",
            "Epoch 262/700\n",
            "317/317 - 1s - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0151 - val_accuracy: 0.9963 - 929ms/epoch - 3ms/step\n",
            "Epoch 263/700\n",
            "317/317 - 1s - loss: 0.0157 - accuracy: 0.9941 - val_loss: 0.0200 - val_accuracy: 0.9944 - 926ms/epoch - 3ms/step\n",
            "Epoch 264/700\n",
            "317/317 - 1s - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.0191 - val_accuracy: 0.9925 - 934ms/epoch - 3ms/step\n",
            "Epoch 265/700\n",
            "317/317 - 1s - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0182 - val_accuracy: 0.9981 - 932ms/epoch - 3ms/step\n",
            "Epoch 266/700\n",
            "317/317 - 1s - loss: 0.0112 - accuracy: 0.9956 - val_loss: 0.0169 - val_accuracy: 0.9963 - 929ms/epoch - 3ms/step\n",
            "Epoch 267/700\n",
            "317/317 - 1s - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0153 - val_accuracy: 0.9944 - 920ms/epoch - 3ms/step\n",
            "Epoch 268/700\n",
            "317/317 - 1s - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0184 - val_accuracy: 0.9963 - 920ms/epoch - 3ms/step\n",
            "Epoch 269/700\n",
            "317/317 - 1s - loss: 0.0151 - accuracy: 0.9941 - val_loss: 0.0177 - val_accuracy: 0.9925 - 946ms/epoch - 3ms/step\n",
            "Epoch 270/700\n",
            "317/317 - 1s - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0247 - val_accuracy: 0.9906 - 929ms/epoch - 3ms/step\n",
            "Epoch 271/700\n",
            "317/317 - 1s - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.0104 - val_accuracy: 0.9963 - 931ms/epoch - 3ms/step\n",
            "Epoch 272/700\n",
            "317/317 - 1s - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.0087 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 273/700\n",
            "317/317 - 1s - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.0173 - val_accuracy: 0.9944 - 942ms/epoch - 3ms/step\n",
            "Epoch 274/700\n",
            "317/317 - 1s - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.0112 - val_accuracy: 0.9925 - 931ms/epoch - 3ms/step\n",
            "Epoch 275/700\n",
            "317/317 - 1s - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.0355 - val_accuracy: 0.9850 - 920ms/epoch - 3ms/step\n",
            "Epoch 276/700\n",
            "317/317 - 1s - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.0201 - val_accuracy: 0.9906 - 910ms/epoch - 3ms/step\n",
            "Epoch 277/700\n",
            "317/317 - 1s - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0141 - val_accuracy: 0.9963 - 911ms/epoch - 3ms/step\n",
            "Epoch 278/700\n",
            "317/317 - 1s - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0241 - val_accuracy: 0.9906 - 919ms/epoch - 3ms/step\n",
            "Epoch 279/700\n",
            "317/317 - 1s - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0126 - val_accuracy: 0.9944 - 926ms/epoch - 3ms/step\n",
            "Epoch 280/700\n",
            "317/317 - 1s - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0110 - val_accuracy: 0.9944 - 928ms/epoch - 3ms/step\n",
            "Epoch 281/700\n",
            "317/317 - 1s - loss: 0.0148 - accuracy: 0.9941 - val_loss: 0.0159 - val_accuracy: 0.9944 - 987ms/epoch - 3ms/step\n",
            "Epoch 282/700\n",
            "317/317 - 1s - loss: 0.0138 - accuracy: 0.9944 - val_loss: 0.0184 - val_accuracy: 0.9944 - 975ms/epoch - 3ms/step\n",
            "Epoch 283/700\n",
            "317/317 - 1s - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0196 - val_accuracy: 0.9906 - 928ms/epoch - 3ms/step\n",
            "Epoch 284/700\n",
            "317/317 - 1s - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.0175 - val_accuracy: 0.9963 - 923ms/epoch - 3ms/step\n",
            "Epoch 285/700\n",
            "317/317 - 1s - loss: 0.0113 - accuracy: 0.9955 - val_loss: 0.0116 - val_accuracy: 0.9963 - 941ms/epoch - 3ms/step\n",
            "Epoch 286/700\n",
            "317/317 - 1s - loss: 0.0140 - accuracy: 0.9948 - val_loss: 0.0187 - val_accuracy: 0.9963 - 927ms/epoch - 3ms/step\n",
            "Epoch 287/700\n",
            "317/317 - 1s - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.0191 - val_accuracy: 0.9944 - 927ms/epoch - 3ms/step\n",
            "Epoch 288/700\n",
            "317/317 - 1s - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0315 - val_accuracy: 0.9888 - 934ms/epoch - 3ms/step\n",
            "Epoch 289/700\n",
            "317/317 - 1s - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0141 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 290/700\n",
            "317/317 - 1s - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0162 - val_accuracy: 0.9944 - 933ms/epoch - 3ms/step\n",
            "Epoch 291/700\n",
            "317/317 - 1s - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0231 - val_accuracy: 0.9963 - 944ms/epoch - 3ms/step\n",
            "Epoch 292/700\n",
            "317/317 - 1s - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.0137 - val_accuracy: 0.9944 - 935ms/epoch - 3ms/step\n",
            "Epoch 293/700\n",
            "317/317 - 1s - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.0355 - val_accuracy: 0.9869 - 929ms/epoch - 3ms/step\n",
            "Epoch 294/700\n",
            "317/317 - 1s - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.0157 - val_accuracy: 0.9944 - 919ms/epoch - 3ms/step\n",
            "Epoch 295/700\n",
            "317/317 - 1s - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.0114 - val_accuracy: 0.9944 - 920ms/epoch - 3ms/step\n",
            "Epoch 296/700\n",
            "317/317 - 1s - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0219 - val_accuracy: 0.9944 - 923ms/epoch - 3ms/step\n",
            "Epoch 297/700\n",
            "317/317 - 1s - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0357 - val_accuracy: 0.9869 - 919ms/epoch - 3ms/step\n",
            "Epoch 298/700\n",
            "317/317 - 1s - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0146 - val_accuracy: 0.9944 - 915ms/epoch - 3ms/step\n",
            "Epoch 299/700\n",
            "317/317 - 1s - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.0132 - val_accuracy: 0.9944 - 931ms/epoch - 3ms/step\n",
            "Epoch 300/700\n",
            "317/317 - 1s - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.0147 - val_accuracy: 0.9944 - 920ms/epoch - 3ms/step\n",
            "Epoch 301/700\n",
            "317/317 - 1s - loss: 0.0129 - accuracy: 0.9945 - val_loss: 0.0241 - val_accuracy: 0.9906 - 933ms/epoch - 3ms/step\n",
            "Epoch 302/700\n",
            "317/317 - 1s - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.0166 - val_accuracy: 0.9944 - 929ms/epoch - 3ms/step\n",
            "Epoch 303/700\n",
            "317/317 - 1s - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0136 - val_accuracy: 0.9963 - 925ms/epoch - 3ms/step\n",
            "Epoch 304/700\n",
            "317/317 - 1s - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.0203 - val_accuracy: 0.9944 - 935ms/epoch - 3ms/step\n",
            "Epoch 305/700\n",
            "317/317 - 1s - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.0173 - val_accuracy: 0.9944 - 936ms/epoch - 3ms/step\n",
            "Epoch 306/700\n",
            "317/317 - 1s - loss: 0.0133 - accuracy: 0.9946 - val_loss: 0.0174 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 307/700\n",
            "317/317 - 1s - loss: 0.0093 - accuracy: 0.9962 - val_loss: 0.0140 - val_accuracy: 0.9963 - 923ms/epoch - 3ms/step\n",
            "Epoch 308/700\n",
            "317/317 - 1s - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0145 - val_accuracy: 0.9963 - 921ms/epoch - 3ms/step\n",
            "Epoch 309/700\n",
            "317/317 - 1s - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.0207 - val_accuracy: 0.9963 - 918ms/epoch - 3ms/step\n",
            "Epoch 310/700\n",
            "317/317 - 1s - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.0208 - val_accuracy: 0.9944 - 923ms/epoch - 3ms/step\n",
            "Epoch 311/700\n",
            "317/317 - 1s - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.0209 - val_accuracy: 0.9944 - 927ms/epoch - 3ms/step\n",
            "Epoch 312/700\n",
            "317/317 - 1s - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0283 - val_accuracy: 0.9925 - 923ms/epoch - 3ms/step\n",
            "Epoch 313/700\n",
            "317/317 - 1s - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0231 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 314/700\n",
            "317/317 - 1s - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0171 - val_accuracy: 0.9944 - 939ms/epoch - 3ms/step\n",
            "Epoch 315/700\n",
            "317/317 - 1s - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0142 - val_accuracy: 0.9944 - 933ms/epoch - 3ms/step\n",
            "Epoch 316/700\n",
            "317/317 - 1s - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.0176 - val_accuracy: 0.9944 - 919ms/epoch - 3ms/step\n",
            "Epoch 317/700\n",
            "317/317 - 1s - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0241 - val_accuracy: 0.9944 - 927ms/epoch - 3ms/step\n",
            "Epoch 318/700\n",
            "317/317 - 1s - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.0177 - val_accuracy: 0.9963 - 926ms/epoch - 3ms/step\n",
            "Epoch 319/700\n",
            "317/317 - 1s - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0189 - val_accuracy: 0.9944 - 917ms/epoch - 3ms/step\n",
            "Epoch 320/700\n",
            "317/317 - 1s - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0150 - val_accuracy: 0.9944 - 935ms/epoch - 3ms/step\n",
            "Epoch 321/700\n",
            "317/317 - 1s - loss: 0.0095 - accuracy: 0.9962 - val_loss: 0.0130 - val_accuracy: 0.9981 - 944ms/epoch - 3ms/step\n",
            "Epoch 322/700\n",
            "317/317 - 1s - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.0126 - val_accuracy: 0.9963 - 923ms/epoch - 3ms/step\n",
            "Epoch 323/700\n",
            "317/317 - 1s - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.0169 - val_accuracy: 0.9944 - 939ms/epoch - 3ms/step\n",
            "Epoch 324/700\n",
            "317/317 - 1s - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0204 - val_accuracy: 0.9944 - 933ms/epoch - 3ms/step\n",
            "Epoch 325/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.0134 - val_accuracy: 0.9944 - 934ms/epoch - 3ms/step\n",
            "Epoch 326/700\n",
            "317/317 - 1s - loss: 0.0112 - accuracy: 0.9955 - val_loss: 0.0341 - val_accuracy: 0.9944 - 938ms/epoch - 3ms/step\n",
            "Epoch 327/700\n",
            "317/317 - 1s - loss: 0.0105 - accuracy: 0.9961 - val_loss: 0.0192 - val_accuracy: 0.9925 - 921ms/epoch - 3ms/step\n",
            "Epoch 328/700\n",
            "317/317 - 1s - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0299 - val_accuracy: 0.9906 - 929ms/epoch - 3ms/step\n",
            "Epoch 329/700\n",
            "317/317 - 1s - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0146 - val_accuracy: 0.9944 - 929ms/epoch - 3ms/step\n",
            "Epoch 330/700\n",
            "317/317 - 1s - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.0224 - val_accuracy: 0.9963 - 927ms/epoch - 3ms/step\n",
            "Epoch 331/700\n",
            "317/317 - 1s - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.0214 - val_accuracy: 0.9944 - 932ms/epoch - 3ms/step\n",
            "Epoch 332/700\n",
            "317/317 - 1s - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0262 - val_accuracy: 0.9944 - 923ms/epoch - 3ms/step\n",
            "Epoch 333/700\n",
            "317/317 - 1s - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.0184 - val_accuracy: 0.9944 - 919ms/epoch - 3ms/step\n",
            "Epoch 334/700\n",
            "317/317 - 1s - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0295 - val_accuracy: 0.9888 - 928ms/epoch - 3ms/step\n",
            "Epoch 335/700\n",
            "317/317 - 1s - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0235 - val_accuracy: 0.9925 - 1s/epoch - 4ms/step\n",
            "Epoch 336/700\n",
            "317/317 - 1s - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0283 - val_accuracy: 0.9944 - 1s/epoch - 4ms/step\n",
            "Epoch 337/700\n",
            "317/317 - 1s - loss: 0.0124 - accuracy: 0.9952 - val_loss: 0.0193 - val_accuracy: 0.9944 - 1s/epoch - 4ms/step\n",
            "Epoch 338/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.0271 - val_accuracy: 0.9906 - 938ms/epoch - 3ms/step\n",
            "Epoch 339/700\n",
            "317/317 - 1s - loss: 0.0092 - accuracy: 0.9964 - val_loss: 0.0256 - val_accuracy: 0.9925 - 954ms/epoch - 3ms/step\n",
            "Epoch 340/700\n",
            "317/317 - 1s - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.0280 - val_accuracy: 0.9944 - 935ms/epoch - 3ms/step\n",
            "Epoch 341/700\n",
            "317/317 - 1s - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0139 - val_accuracy: 0.9944 - 925ms/epoch - 3ms/step\n",
            "Epoch 342/700\n",
            "317/317 - 1s - loss: 0.0146 - accuracy: 0.9941 - val_loss: 0.0407 - val_accuracy: 0.9906 - 910ms/epoch - 3ms/step\n",
            "Epoch 343/700\n",
            "317/317 - 1s - loss: 0.0149 - accuracy: 0.9933 - val_loss: 0.0110 - val_accuracy: 0.9981 - 913ms/epoch - 3ms/step\n",
            "Epoch 344/700\n",
            "317/317 - 1s - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0210 - val_accuracy: 0.9925 - 941ms/epoch - 3ms/step\n",
            "Epoch 345/700\n",
            "317/317 - 1s - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.0108 - val_accuracy: 0.9944 - 935ms/epoch - 3ms/step\n",
            "Epoch 346/700\n",
            "317/317 - 1s - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0178 - val_accuracy: 0.9963 - 926ms/epoch - 3ms/step\n",
            "Epoch 347/700\n",
            "317/317 - 1s - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0110 - val_accuracy: 0.9944 - 954ms/epoch - 3ms/step\n",
            "Epoch 348/700\n",
            "317/317 - 1s - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.0235 - val_accuracy: 0.9963 - 917ms/epoch - 3ms/step\n",
            "Epoch 349/700\n",
            "317/317 - 1s - loss: 0.0096 - accuracy: 0.9965 - val_loss: 0.0163 - val_accuracy: 0.9963 - 913ms/epoch - 3ms/step\n",
            "Epoch 350/700\n",
            "317/317 - 1s - loss: 0.0111 - accuracy: 0.9954 - val_loss: 0.0226 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 351/700\n",
            "317/317 - 1s - loss: 0.0110 - accuracy: 0.9953 - val_loss: 0.0239 - val_accuracy: 0.9963 - 913ms/epoch - 3ms/step\n",
            "Epoch 352/700\n",
            "317/317 - 1s - loss: 0.0097 - accuracy: 0.9961 - val_loss: 0.0162 - val_accuracy: 0.9944 - 913ms/epoch - 3ms/step\n",
            "Epoch 353/700\n",
            "317/317 - 1s - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0142 - val_accuracy: 0.9944 - 908ms/epoch - 3ms/step\n",
            "Epoch 354/700\n",
            "317/317 - 1s - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0209 - val_accuracy: 0.9944 - 908ms/epoch - 3ms/step\n",
            "Epoch 355/700\n",
            "317/317 - 1s - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.0240 - val_accuracy: 0.9906 - 935ms/epoch - 3ms/step\n",
            "Epoch 356/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0345 - val_accuracy: 0.9906 - 935ms/epoch - 3ms/step\n",
            "Epoch 357/700\n",
            "317/317 - 1s - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0224 - val_accuracy: 0.9925 - 936ms/epoch - 3ms/step\n",
            "Epoch 358/700\n",
            "317/317 - 1s - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.0152 - val_accuracy: 0.9944 - 939ms/epoch - 3ms/step\n",
            "Epoch 359/700\n",
            "317/317 - 1s - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.0220 - val_accuracy: 0.9944 - 911ms/epoch - 3ms/step\n",
            "Epoch 360/700\n",
            "317/317 - 1s - loss: 0.0095 - accuracy: 0.9964 - val_loss: 0.0237 - val_accuracy: 0.9944 - 922ms/epoch - 3ms/step\n",
            "Epoch 361/700\n",
            "317/317 - 1s - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0219 - val_accuracy: 0.9944 - 929ms/epoch - 3ms/step\n",
            "Epoch 362/700\n",
            "317/317 - 1s - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.0219 - val_accuracy: 0.9944 - 926ms/epoch - 3ms/step\n",
            "Epoch 363/700\n",
            "317/317 - 1s - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0232 - val_accuracy: 0.9906 - 924ms/epoch - 3ms/step\n",
            "Epoch 364/700\n",
            "317/317 - 1s - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0185 - val_accuracy: 0.9944 - 929ms/epoch - 3ms/step\n",
            "Epoch 365/700\n",
            "317/317 - 1s - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0158 - val_accuracy: 0.9963 - 943ms/epoch - 3ms/step\n",
            "Epoch 366/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0160 - val_accuracy: 0.9963 - 920ms/epoch - 3ms/step\n",
            "Epoch 367/700\n",
            "317/317 - 1s - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.0178 - val_accuracy: 0.9944 - 959ms/epoch - 3ms/step\n",
            "Epoch 368/700\n",
            "317/317 - 1s - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0255 - val_accuracy: 0.9906 - 937ms/epoch - 3ms/step\n",
            "Epoch 369/700\n",
            "317/317 - 1s - loss: 0.0079 - accuracy: 0.9969 - val_loss: 0.0219 - val_accuracy: 0.9925 - 929ms/epoch - 3ms/step\n",
            "Epoch 370/700\n",
            "317/317 - 1s - loss: 0.0113 - accuracy: 0.9955 - val_loss: 0.0115 - val_accuracy: 0.9944 - 925ms/epoch - 3ms/step\n",
            "Epoch 371/700\n",
            "317/317 - 1s - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0117 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 372/700\n",
            "317/317 - 1s - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.0225 - val_accuracy: 0.9944 - 922ms/epoch - 3ms/step\n",
            "Epoch 373/700\n",
            "317/317 - 1s - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0178 - val_accuracy: 0.9925 - 921ms/epoch - 3ms/step\n",
            "Epoch 374/700\n",
            "317/317 - 1s - loss: 0.0117 - accuracy: 0.9955 - val_loss: 0.0163 - val_accuracy: 0.9963 - 922ms/epoch - 3ms/step\n",
            "Epoch 375/700\n",
            "317/317 - 1s - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0159 - val_accuracy: 0.9944 - 918ms/epoch - 3ms/step\n",
            "Epoch 376/700\n",
            "317/317 - 1s - loss: 0.0101 - accuracy: 0.9962 - val_loss: 0.0186 - val_accuracy: 0.9963 - 918ms/epoch - 3ms/step\n",
            "Epoch 377/700\n",
            "317/317 - 1s - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.0134 - val_accuracy: 0.9963 - 919ms/epoch - 3ms/step\n",
            "Epoch 378/700\n",
            "317/317 - 1s - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0132 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 379/700\n",
            "317/317 - 1s - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0206 - val_accuracy: 0.9925 - 918ms/epoch - 3ms/step\n",
            "Epoch 380/700\n",
            "317/317 - 1s - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0211 - val_accuracy: 0.9944 - 919ms/epoch - 3ms/step\n",
            "Epoch 381/700\n",
            "317/317 - 1s - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0197 - val_accuracy: 0.9981 - 915ms/epoch - 3ms/step\n",
            "Epoch 382/700\n",
            "317/317 - 1s - loss: 0.0092 - accuracy: 0.9975 - val_loss: 0.0154 - val_accuracy: 0.9944 - 934ms/epoch - 3ms/step\n",
            "Epoch 383/700\n",
            "317/317 - 1s - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.0146 - val_accuracy: 0.9981 - 930ms/epoch - 3ms/step\n",
            "Epoch 384/700\n",
            "317/317 - 1s - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.0310 - val_accuracy: 0.9944 - 943ms/epoch - 3ms/step\n",
            "Epoch 385/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9960 - val_loss: 0.0191 - val_accuracy: 0.9944 - 907ms/epoch - 3ms/step\n",
            "Epoch 386/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.0211 - val_accuracy: 0.9944 - 913ms/epoch - 3ms/step\n",
            "Epoch 387/700\n",
            "317/317 - 1s - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.0166 - val_accuracy: 0.9925 - 923ms/epoch - 3ms/step\n",
            "Epoch 388/700\n",
            "317/317 - 1s - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.0238 - val_accuracy: 0.9944 - 911ms/epoch - 3ms/step\n",
            "Epoch 389/700\n",
            "317/317 - 1s - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.0243 - val_accuracy: 0.9925 - 944ms/epoch - 3ms/step\n",
            "Epoch 390/700\n",
            "317/317 - 1s - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0158 - val_accuracy: 0.9944 - 928ms/epoch - 3ms/step\n",
            "Epoch 391/700\n",
            "317/317 - 1s - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0258 - val_accuracy: 0.9925 - 926ms/epoch - 3ms/step\n",
            "Epoch 392/700\n",
            "317/317 - 1s - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.0252 - val_accuracy: 0.9925 - 909ms/epoch - 3ms/step\n",
            "Epoch 393/700\n",
            "317/317 - 1s - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0168 - val_accuracy: 0.9944 - 906ms/epoch - 3ms/step\n",
            "Epoch 394/700\n",
            "317/317 - 1s - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0192 - val_accuracy: 0.9944 - 908ms/epoch - 3ms/step\n",
            "Epoch 395/700\n",
            "317/317 - 1s - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.0211 - val_accuracy: 0.9944 - 907ms/epoch - 3ms/step\n",
            "Epoch 396/700\n",
            "317/317 - 1s - loss: 0.0108 - accuracy: 0.9960 - val_loss: 0.0236 - val_accuracy: 0.9944 - 916ms/epoch - 3ms/step\n",
            "Epoch 397/700\n",
            "317/317 - 1s - loss: 0.0106 - accuracy: 0.9956 - val_loss: 0.0174 - val_accuracy: 0.9944 - 921ms/epoch - 3ms/step\n",
            "Epoch 398/700\n",
            "317/317 - 1s - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0194 - val_accuracy: 0.9963 - 898ms/epoch - 3ms/step\n",
            "Epoch 399/700\n",
            "317/317 - 1s - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0172 - val_accuracy: 0.9981 - 898ms/epoch - 3ms/step\n",
            "Epoch 400/700\n",
            "317/317 - 1s - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.0202 - val_accuracy: 0.9944 - 899ms/epoch - 3ms/step\n",
            "Epoch 401/700\n",
            "317/317 - 1s - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0159 - val_accuracy: 0.9963 - 910ms/epoch - 3ms/step\n",
            "Epoch 402/700\n",
            "317/317 - 1s - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.0175 - val_accuracy: 0.9981 - 901ms/epoch - 3ms/step\n",
            "Epoch 403/700\n",
            "317/317 - 1s - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.0193 - val_accuracy: 0.9925 - 930ms/epoch - 3ms/step\n",
            "Epoch 404/700\n",
            "317/317 - 1s - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0187 - val_accuracy: 0.9981 - 919ms/epoch - 3ms/step\n",
            "Epoch 405/700\n",
            "317/317 - 1s - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.0410 - val_accuracy: 0.9888 - 903ms/epoch - 3ms/step\n",
            "Epoch 406/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9961 - val_loss: 0.0182 - val_accuracy: 0.9963 - 906ms/epoch - 3ms/step\n",
            "Epoch 407/700\n",
            "317/317 - 1s - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.0214 - val_accuracy: 0.9944 - 912ms/epoch - 3ms/step\n",
            "Epoch 408/700\n",
            "317/317 - 1s - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.0248 - val_accuracy: 0.9944 - 908ms/epoch - 3ms/step\n",
            "Epoch 409/700\n",
            "317/317 - 1s - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0157 - val_accuracy: 0.9944 - 921ms/epoch - 3ms/step\n",
            "Epoch 410/700\n",
            "317/317 - 1s - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.0101 - val_accuracy: 0.9963 - 912ms/epoch - 3ms/step\n",
            "Epoch 411/700\n",
            "317/317 - 1s - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.0195 - val_accuracy: 0.9944 - 903ms/epoch - 3ms/step\n",
            "Epoch 412/700\n",
            "317/317 - 1s - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0205 - val_accuracy: 0.9944 - 910ms/epoch - 3ms/step\n",
            "Epoch 413/700\n",
            "317/317 - 1s - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0276 - val_accuracy: 0.9944 - 907ms/epoch - 3ms/step\n",
            "Epoch 414/700\n",
            "317/317 - 1s - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0281 - val_accuracy: 0.9925 - 914ms/epoch - 3ms/step\n",
            "Epoch 415/700\n",
            "317/317 - 1s - loss: 0.0059 - accuracy: 0.9975 - val_loss: 0.0199 - val_accuracy: 0.9944 - 954ms/epoch - 3ms/step\n",
            "Epoch 416/700\n",
            "317/317 - 1s - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.0273 - val_accuracy: 0.9963 - 905ms/epoch - 3ms/step\n",
            "Epoch 417/700\n",
            "317/317 - 1s - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0180 - val_accuracy: 0.9981 - 895ms/epoch - 3ms/step\n",
            "Epoch 418/700\n",
            "317/317 - 1s - loss: 0.0105 - accuracy: 0.9962 - val_loss: 0.0304 - val_accuracy: 0.9944 - 915ms/epoch - 3ms/step\n",
            "Epoch 419/700\n",
            "317/317 - 1s - loss: 0.0078 - accuracy: 0.9969 - val_loss: 0.0201 - val_accuracy: 0.9963 - 913ms/epoch - 3ms/step\n",
            "Epoch 420/700\n",
            "317/317 - 1s - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0250 - val_accuracy: 0.9944 - 898ms/epoch - 3ms/step\n",
            "Epoch 421/700\n",
            "317/317 - 1s - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0269 - val_accuracy: 0.9963 - 911ms/epoch - 3ms/step\n",
            "Epoch 422/700\n",
            "317/317 - 1s - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.0323 - val_accuracy: 0.9944 - 897ms/epoch - 3ms/step\n",
            "Epoch 423/700\n",
            "317/317 - 1s - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.0197 - val_accuracy: 0.9944 - 905ms/epoch - 3ms/step\n",
            "Epoch 424/700\n",
            "317/317 - 1s - loss: 0.0110 - accuracy: 0.9955 - val_loss: 0.0665 - val_accuracy: 0.9850 - 917ms/epoch - 3ms/step\n",
            "Epoch 425/700\n",
            "317/317 - 1s - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.0211 - val_accuracy: 0.9944 - 949ms/epoch - 3ms/step\n",
            "Epoch 426/700\n",
            "317/317 - 1s - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0166 - val_accuracy: 0.9981 - 917ms/epoch - 3ms/step\n",
            "Epoch 427/700\n",
            "317/317 - 1s - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0209 - val_accuracy: 0.9963 - 931ms/epoch - 3ms/step\n",
            "Epoch 428/700\n",
            "317/317 - 1s - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0202 - val_accuracy: 0.9944 - 942ms/epoch - 3ms/step\n",
            "Epoch 429/700\n",
            "317/317 - 1s - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0262 - val_accuracy: 0.9944 - 942ms/epoch - 3ms/step\n",
            "Epoch 430/700\n",
            "317/317 - 1s - loss: 0.0100 - accuracy: 0.9959 - val_loss: 0.0213 - val_accuracy: 0.9925 - 971ms/epoch - 3ms/step\n",
            "Epoch 431/700\n",
            "317/317 - 1s - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9925 - 944ms/epoch - 3ms/step\n",
            "Epoch 432/700\n",
            "317/317 - 1s - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.0196 - val_accuracy: 0.9925 - 949ms/epoch - 3ms/step\n",
            "Epoch 433/700\n",
            "317/317 - 1s - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0219 - val_accuracy: 0.9944 - 957ms/epoch - 3ms/step\n",
            "Epoch 434/700\n",
            "317/317 - 1s - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0255 - val_accuracy: 0.9944 - 943ms/epoch - 3ms/step\n",
            "Epoch 435/700\n",
            "317/317 - 1s - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0249 - val_accuracy: 0.9944 - 952ms/epoch - 3ms/step\n",
            "Epoch 436/700\n",
            "317/317 - 1s - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0170 - val_accuracy: 0.9944 - 956ms/epoch - 3ms/step\n",
            "Epoch 437/700\n",
            "317/317 - 1s - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.0253 - val_accuracy: 0.9944 - 946ms/epoch - 3ms/step\n",
            "Epoch 438/700\n",
            "317/317 - 1s - loss: 0.0085 - accuracy: 0.9967 - val_loss: 0.0256 - val_accuracy: 0.9963 - 963ms/epoch - 3ms/step\n",
            "Epoch 439/700\n",
            "317/317 - 1s - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0243 - val_accuracy: 0.9944 - 972ms/epoch - 3ms/step\n",
            "Epoch 440/700\n",
            "317/317 - 1s - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0261 - val_accuracy: 0.9963 - 935ms/epoch - 3ms/step\n",
            "Epoch 441/700\n",
            "317/317 - 1s - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0199 - val_accuracy: 0.9981 - 947ms/epoch - 3ms/step\n",
            "Epoch 442/700\n",
            "317/317 - 1s - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.0158 - val_accuracy: 0.9944 - 927ms/epoch - 3ms/step\n",
            "Epoch 443/700\n",
            "317/317 - 1s - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.0159 - val_accuracy: 0.9944 - 940ms/epoch - 3ms/step\n",
            "Epoch 444/700\n",
            "317/317 - 1s - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0193 - val_accuracy: 0.9963 - 945ms/epoch - 3ms/step\n",
            "Epoch 445/700\n",
            "317/317 - 1s - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0203 - val_accuracy: 0.9944 - 931ms/epoch - 3ms/step\n",
            "Epoch 446/700\n",
            "317/317 - 1s - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.0233 - val_accuracy: 0.9944 - 924ms/epoch - 3ms/step\n",
            "Epoch 447/700\n",
            "317/317 - 1s - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0210 - val_accuracy: 0.9944 - 923ms/epoch - 3ms/step\n",
            "Epoch 448/700\n",
            "317/317 - 1s - loss: 0.0130 - accuracy: 0.9950 - val_loss: 0.0248 - val_accuracy: 0.9963 - 925ms/epoch - 3ms/step\n",
            "Epoch 449/700\n",
            "317/317 - 1s - loss: 0.0111 - accuracy: 0.9956 - val_loss: 0.0219 - val_accuracy: 0.9981 - 923ms/epoch - 3ms/step\n",
            "Epoch 450/700\n",
            "317/317 - 1s - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0278 - val_accuracy: 0.9925 - 921ms/epoch - 3ms/step\n",
            "Epoch 451/700\n",
            "317/317 - 1s - loss: 0.0082 - accuracy: 0.9962 - val_loss: 0.0207 - val_accuracy: 0.9963 - 922ms/epoch - 3ms/step\n",
            "Epoch 452/700\n",
            "317/317 - 1s - loss: 0.0073 - accuracy: 0.9967 - val_loss: 0.0233 - val_accuracy: 0.9944 - 935ms/epoch - 3ms/step\n",
            "Epoch 453/700\n",
            "317/317 - 1s - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0430 - val_accuracy: 0.9850 - 931ms/epoch - 3ms/step\n",
            "Epoch 454/700\n",
            "317/317 - 1s - loss: 0.0113 - accuracy: 0.9955 - val_loss: 0.0147 - val_accuracy: 0.9944 - 944ms/epoch - 3ms/step\n",
            "Epoch 455/700\n",
            "317/317 - 1s - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0221 - val_accuracy: 0.9925 - 932ms/epoch - 3ms/step\n",
            "Epoch 456/700\n",
            "317/317 - 1s - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0176 - val_accuracy: 0.9963 - 918ms/epoch - 3ms/step\n",
            "Epoch 457/700\n",
            "317/317 - 1s - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.0203 - val_accuracy: 0.9981 - 919ms/epoch - 3ms/step\n",
            "Epoch 458/700\n",
            "317/317 - 1s - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0241 - val_accuracy: 0.9944 - 944ms/epoch - 3ms/step\n",
            "Epoch 459/700\n",
            "317/317 - 1s - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.0186 - val_accuracy: 0.9944 - 925ms/epoch - 3ms/step\n",
            "Epoch 460/700\n",
            "317/317 - 1s - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0208 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 461/700\n",
            "317/317 - 1s - loss: 0.0065 - accuracy: 0.9975 - val_loss: 0.0292 - val_accuracy: 0.9944 - 927ms/epoch - 3ms/step\n",
            "Epoch 462/700\n",
            "317/317 - 1s - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0244 - val_accuracy: 0.9944 - 920ms/epoch - 3ms/step\n",
            "Epoch 463/700\n",
            "317/317 - 1s - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.0219 - val_accuracy: 0.9963 - 944ms/epoch - 3ms/step\n",
            "Epoch 464/700\n",
            "317/317 - 1s - loss: 0.0054 - accuracy: 0.9975 - val_loss: 0.0277 - val_accuracy: 0.9944 - 914ms/epoch - 3ms/step\n",
            "Epoch 465/700\n",
            "317/317 - 1s - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.0232 - val_accuracy: 0.9944 - 915ms/epoch - 3ms/step\n",
            "Epoch 466/700\n",
            "317/317 - 1s - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0242 - val_accuracy: 0.9944 - 902ms/epoch - 3ms/step\n",
            "Epoch 467/700\n",
            "317/317 - 1s - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.0182 - val_accuracy: 0.9925 - 902ms/epoch - 3ms/step\n",
            "Epoch 468/700\n",
            "317/317 - 1s - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.0073 - val_accuracy: 0.9981 - 916ms/epoch - 3ms/step\n",
            "Epoch 469/700\n",
            "317/317 - 1s - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0128 - val_accuracy: 0.9963 - 912ms/epoch - 3ms/step\n",
            "Epoch 470/700\n",
            "317/317 - 1s - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0270 - val_accuracy: 0.9963 - 922ms/epoch - 3ms/step\n",
            "Epoch 471/700\n",
            "317/317 - 1s - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0171 - val_accuracy: 0.9963 - 915ms/epoch - 3ms/step\n",
            "Epoch 472/700\n",
            "317/317 - 1s - loss: 0.0081 - accuracy: 0.9967 - val_loss: 0.0277 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 473/700\n",
            "317/317 - 1s - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0164 - val_accuracy: 0.9944 - 902ms/epoch - 3ms/step\n",
            "Epoch 474/700\n",
            "317/317 - 1s - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.0412 - val_accuracy: 0.9925 - 929ms/epoch - 3ms/step\n",
            "Epoch 475/700\n",
            "317/317 - 1s - loss: 0.0080 - accuracy: 0.9969 - val_loss: 0.0245 - val_accuracy: 0.9944 - 924ms/epoch - 3ms/step\n",
            "Epoch 476/700\n",
            "317/317 - 1s - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.0187 - val_accuracy: 0.9944 - 929ms/epoch - 3ms/step\n",
            "Epoch 477/700\n",
            "317/317 - 1s - loss: 0.0086 - accuracy: 0.9967 - val_loss: 0.0314 - val_accuracy: 0.9925 - 937ms/epoch - 3ms/step\n",
            "Epoch 478/700\n",
            "317/317 - 1s - loss: 0.0077 - accuracy: 0.9969 - val_loss: 0.0263 - val_accuracy: 0.9944 - 941ms/epoch - 3ms/step\n",
            "Epoch 479/700\n",
            "317/317 - 1s - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0270 - val_accuracy: 0.9963 - 912ms/epoch - 3ms/step\n",
            "Epoch 480/700\n",
            "317/317 - 1s - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.0282 - val_accuracy: 0.9963 - 939ms/epoch - 3ms/step\n",
            "Epoch 481/700\n",
            "317/317 - 1s - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0259 - val_accuracy: 0.9944 - 931ms/epoch - 3ms/step\n",
            "Epoch 482/700\n",
            "317/317 - 1s - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0182 - val_accuracy: 0.9981 - 924ms/epoch - 3ms/step\n",
            "Epoch 483/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9961 - val_loss: 0.0146 - val_accuracy: 0.9963 - 920ms/epoch - 3ms/step\n",
            "Epoch 484/700\n",
            "317/317 - 1s - loss: 0.0065 - accuracy: 0.9969 - val_loss: 0.0096 - val_accuracy: 0.9981 - 918ms/epoch - 3ms/step\n",
            "Epoch 485/700\n",
            "317/317 - 1s - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0166 - val_accuracy: 0.9963 - 929ms/epoch - 3ms/step\n",
            "Epoch 486/700\n",
            "317/317 - 1s - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0183 - val_accuracy: 0.9906 - 915ms/epoch - 3ms/step\n",
            "Epoch 487/700\n",
            "317/317 - 1s - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0156 - val_accuracy: 0.9981 - 931ms/epoch - 3ms/step\n",
            "Epoch 488/700\n",
            "317/317 - 1s - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.0180 - val_accuracy: 0.9963 - 918ms/epoch - 3ms/step\n",
            "Epoch 489/700\n",
            "317/317 - 1s - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0291 - val_accuracy: 0.9944 - 918ms/epoch - 3ms/step\n",
            "Epoch 490/700\n",
            "317/317 - 1s - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0212 - val_accuracy: 0.9963 - 942ms/epoch - 3ms/step\n",
            "Epoch 491/700\n",
            "317/317 - 1s - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0227 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 492/700\n",
            "317/317 - 1s - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.0184 - val_accuracy: 0.9963 - 926ms/epoch - 3ms/step\n",
            "Epoch 493/700\n",
            "317/317 - 1s - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.0201 - val_accuracy: 0.9963 - 933ms/epoch - 3ms/step\n",
            "Epoch 494/700\n",
            "317/317 - 1s - loss: 0.0101 - accuracy: 0.9962 - val_loss: 0.0253 - val_accuracy: 0.9963 - 951ms/epoch - 3ms/step\n",
            "Epoch 495/700\n",
            "317/317 - 1s - loss: 0.0085 - accuracy: 0.9965 - val_loss: 0.0286 - val_accuracy: 0.9944 - 931ms/epoch - 3ms/step\n",
            "Epoch 496/700\n",
            "317/317 - 1s - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0242 - val_accuracy: 0.9963 - 942ms/epoch - 3ms/step\n",
            "Epoch 497/700\n",
            "317/317 - 1s - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0211 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 498/700\n",
            "317/317 - 1s - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.0114 - val_accuracy: 0.9981 - 916ms/epoch - 3ms/step\n",
            "Epoch 499/700\n",
            "317/317 - 1s - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0168 - val_accuracy: 0.9963 - 929ms/epoch - 3ms/step\n",
            "Epoch 500/700\n",
            "317/317 - 1s - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.0306 - val_accuracy: 0.9944 - 934ms/epoch - 3ms/step\n",
            "Epoch 501/700\n",
            "317/317 - 1s - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.0309 - val_accuracy: 0.9925 - 921ms/epoch - 3ms/step\n",
            "Epoch 502/700\n",
            "317/317 - 1s - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0214 - val_accuracy: 0.9925 - 931ms/epoch - 3ms/step\n",
            "Epoch 503/700\n",
            "317/317 - 1s - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0306 - val_accuracy: 0.9906 - 921ms/epoch - 3ms/step\n",
            "Epoch 504/700\n",
            "317/317 - 1s - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0298 - val_accuracy: 0.9944 - 934ms/epoch - 3ms/step\n",
            "Epoch 505/700\n",
            "317/317 - 1s - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0195 - val_accuracy: 0.9944 - 943ms/epoch - 3ms/step\n",
            "Epoch 506/700\n",
            "317/317 - 1s - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0288 - val_accuracy: 0.9963 - 937ms/epoch - 3ms/step\n",
            "Epoch 507/700\n",
            "317/317 - 1s - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.0239 - val_accuracy: 0.9963 - 923ms/epoch - 3ms/step\n",
            "Epoch 508/700\n",
            "317/317 - 1s - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0174 - val_accuracy: 0.9944 - 911ms/epoch - 3ms/step\n",
            "Epoch 509/700\n",
            "317/317 - 1s - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0273 - val_accuracy: 0.9963 - 927ms/epoch - 3ms/step\n",
            "Epoch 510/700\n",
            "317/317 - 1s - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0356 - val_accuracy: 0.9925 - 918ms/epoch - 3ms/step\n",
            "Epoch 511/700\n",
            "317/317 - 1s - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0279 - val_accuracy: 0.9925 - 923ms/epoch - 3ms/step\n",
            "Epoch 512/700\n",
            "317/317 - 1s - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0246 - val_accuracy: 0.9963 - 910ms/epoch - 3ms/step\n",
            "Epoch 513/700\n",
            "317/317 - 1s - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0247 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 514/700\n",
            "317/317 - 1s - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.0256 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 515/700\n",
            "317/317 - 1s - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0231 - val_accuracy: 0.9963 - 910ms/epoch - 3ms/step\n",
            "Epoch 516/700\n",
            "317/317 - 1s - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0188 - val_accuracy: 0.9963 - 929ms/epoch - 3ms/step\n",
            "Epoch 517/700\n",
            "317/317 - 1s - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.0305 - val_accuracy: 0.9925 - 939ms/epoch - 3ms/step\n",
            "Epoch 518/700\n",
            "317/317 - 1s - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0314 - val_accuracy: 0.9963 - 921ms/epoch - 3ms/step\n",
            "Epoch 519/700\n",
            "317/317 - 1s - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0300 - val_accuracy: 0.9944 - 915ms/epoch - 3ms/step\n",
            "Epoch 520/700\n",
            "317/317 - 1s - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0264 - val_accuracy: 0.9963 - 914ms/epoch - 3ms/step\n",
            "Epoch 521/700\n",
            "317/317 - 1s - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0329 - val_accuracy: 0.9906 - 932ms/epoch - 3ms/step\n",
            "Epoch 522/700\n",
            "317/317 - 1s - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0213 - val_accuracy: 0.9963 - 922ms/epoch - 3ms/step\n",
            "Epoch 523/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.0259 - val_accuracy: 0.9963 - 949ms/epoch - 3ms/step\n",
            "Epoch 524/700\n",
            "317/317 - 1s - loss: 0.0071 - accuracy: 0.9971 - val_loss: 0.0220 - val_accuracy: 0.9944 - 910ms/epoch - 3ms/step\n",
            "Epoch 525/700\n",
            "317/317 - 1s - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0228 - val_accuracy: 0.9944 - 912ms/epoch - 3ms/step\n",
            "Epoch 526/700\n",
            "317/317 - 1s - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0261 - val_accuracy: 0.9944 - 921ms/epoch - 3ms/step\n",
            "Epoch 527/700\n",
            "317/317 - 1s - loss: 0.0072 - accuracy: 0.9971 - val_loss: 0.0272 - val_accuracy: 0.9944 - 922ms/epoch - 3ms/step\n",
            "Epoch 528/700\n",
            "317/317 - 1s - loss: 0.0060 - accuracy: 0.9972 - val_loss: 0.0210 - val_accuracy: 0.9981 - 946ms/epoch - 3ms/step\n",
            "Epoch 529/700\n",
            "317/317 - 1s - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0297 - val_accuracy: 0.9963 - 918ms/epoch - 3ms/step\n",
            "Epoch 530/700\n",
            "317/317 - 1s - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.0214 - val_accuracy: 0.9963 - 941ms/epoch - 3ms/step\n",
            "Epoch 531/700\n",
            "317/317 - 1s - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0218 - val_accuracy: 0.9963 - 912ms/epoch - 3ms/step\n",
            "Epoch 532/700\n",
            "317/317 - 1s - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0241 - val_accuracy: 0.9944 - 917ms/epoch - 3ms/step\n",
            "Epoch 533/700\n",
            "317/317 - 1s - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0319 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 534/700\n",
            "317/317 - 1s - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0220 - val_accuracy: 0.9963 - 923ms/epoch - 3ms/step\n",
            "Epoch 535/700\n",
            "317/317 - 1s - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0326 - val_accuracy: 0.9963 - 914ms/epoch - 3ms/step\n",
            "Epoch 536/700\n",
            "317/317 - 1s - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0261 - val_accuracy: 0.9944 - 913ms/epoch - 3ms/step\n",
            "Epoch 537/700\n",
            "317/317 - 1s - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.0258 - val_accuracy: 0.9944 - 935ms/epoch - 3ms/step\n",
            "Epoch 538/700\n",
            "317/317 - 1s - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0390 - val_accuracy: 0.9963 - 945ms/epoch - 3ms/step\n",
            "Epoch 539/700\n",
            "317/317 - 1s - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.0297 - val_accuracy: 0.9963 - 952ms/epoch - 3ms/step\n",
            "Epoch 540/700\n",
            "317/317 - 1s - loss: 0.0075 - accuracy: 0.9971 - val_loss: 0.0325 - val_accuracy: 0.9944 - 928ms/epoch - 3ms/step\n",
            "Epoch 541/700\n",
            "317/317 - 1s - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0280 - val_accuracy: 0.9963 - 948ms/epoch - 3ms/step\n",
            "Epoch 542/700\n",
            "317/317 - 1s - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.0089 - val_accuracy: 0.9963 - 927ms/epoch - 3ms/step\n",
            "Epoch 543/700\n",
            "317/317 - 1s - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0235 - val_accuracy: 0.9963 - 923ms/epoch - 3ms/step\n",
            "Epoch 544/700\n",
            "317/317 - 1s - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.0232 - val_accuracy: 0.9963 - 916ms/epoch - 3ms/step\n",
            "Epoch 545/700\n",
            "317/317 - 1s - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0337 - val_accuracy: 0.9906 - 944ms/epoch - 3ms/step\n",
            "Epoch 546/700\n",
            "317/317 - 1s - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0184 - val_accuracy: 0.9925 - 943ms/epoch - 3ms/step\n",
            "Epoch 547/700\n",
            "317/317 - 1s - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0270 - val_accuracy: 0.9963 - 917ms/epoch - 3ms/step\n",
            "Epoch 548/700\n",
            "317/317 - 1s - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0224 - val_accuracy: 0.9963 - 914ms/epoch - 3ms/step\n",
            "Epoch 549/700\n",
            "317/317 - 1s - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.0335 - val_accuracy: 0.9944 - 925ms/epoch - 3ms/step\n",
            "Epoch 550/700\n",
            "317/317 - 1s - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.0221 - val_accuracy: 0.9963 - 922ms/epoch - 3ms/step\n",
            "Epoch 551/700\n",
            "317/317 - 1s - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0165 - val_accuracy: 0.9963 - 941ms/epoch - 3ms/step\n",
            "Epoch 552/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.0136 - val_accuracy: 0.9963 - 941ms/epoch - 3ms/step\n",
            "Epoch 553/700\n",
            "317/317 - 1s - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0219 - val_accuracy: 0.9963 - 922ms/epoch - 3ms/step\n",
            "Epoch 554/700\n",
            "317/317 - 1s - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.0281 - val_accuracy: 0.9963 - 918ms/epoch - 3ms/step\n",
            "Epoch 555/700\n",
            "317/317 - 1s - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0281 - val_accuracy: 0.9963 - 914ms/epoch - 3ms/step\n",
            "Epoch 556/700\n",
            "317/317 - 1s - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.0225 - val_accuracy: 0.9944 - 917ms/epoch - 3ms/step\n",
            "Epoch 557/700\n",
            "317/317 - 1s - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0346 - val_accuracy: 0.9944 - 917ms/epoch - 3ms/step\n",
            "Epoch 558/700\n",
            "317/317 - 1s - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0226 - val_accuracy: 0.9944 - 918ms/epoch - 3ms/step\n",
            "Epoch 559/700\n",
            "317/317 - 1s - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0207 - val_accuracy: 0.9944 - 924ms/epoch - 3ms/step\n",
            "Epoch 560/700\n",
            "317/317 - 1s - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0279 - val_accuracy: 0.9944 - 926ms/epoch - 3ms/step\n",
            "Epoch 561/700\n",
            "317/317 - 1s - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0246 - val_accuracy: 0.9963 - 944ms/epoch - 3ms/step\n",
            "Epoch 562/700\n",
            "317/317 - 1s - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0242 - val_accuracy: 0.9944 - 932ms/epoch - 3ms/step\n",
            "Epoch 563/700\n",
            "317/317 - 1s - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.0287 - val_accuracy: 0.9944 - 946ms/epoch - 3ms/step\n",
            "Epoch 564/700\n",
            "317/317 - 1s - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.0294 - val_accuracy: 0.9944 - 908ms/epoch - 3ms/step\n",
            "Epoch 565/700\n",
            "317/317 - 1s - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0280 - val_accuracy: 0.9963 - 918ms/epoch - 3ms/step\n",
            "Epoch 566/700\n",
            "317/317 - 1s - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0268 - val_accuracy: 0.9963 - 912ms/epoch - 3ms/step\n",
            "Epoch 567/700\n",
            "317/317 - 1s - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.0278 - val_accuracy: 0.9963 - 920ms/epoch - 3ms/step\n",
            "Epoch 568/700\n",
            "317/317 - 1s - loss: 0.0046 - accuracy: 0.9981 - val_loss: 0.0312 - val_accuracy: 0.9944 - 918ms/epoch - 3ms/step\n",
            "Epoch 569/700\n",
            "317/317 - 1s - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0345 - val_accuracy: 0.9944 - 920ms/epoch - 3ms/step\n",
            "Epoch 570/700\n",
            "317/317 - 1s - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.0412 - val_accuracy: 0.9906 - 922ms/epoch - 3ms/step\n",
            "Epoch 571/700\n",
            "317/317 - 1s - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.0331 - val_accuracy: 0.9925 - 925ms/epoch - 3ms/step\n",
            "Epoch 572/700\n",
            "317/317 - 1s - loss: 0.0054 - accuracy: 0.9977 - val_loss: 0.0299 - val_accuracy: 0.9925 - 928ms/epoch - 3ms/step\n",
            "Epoch 573/700\n",
            "317/317 - 1s - loss: 0.0076 - accuracy: 0.9967 - val_loss: 0.0389 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 574/700\n",
            "317/317 - 1s - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0342 - val_accuracy: 0.9963 - 918ms/epoch - 3ms/step\n",
            "Epoch 575/700\n",
            "317/317 - 1s - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0231 - val_accuracy: 0.9963 - 929ms/epoch - 3ms/step\n",
            "Epoch 576/700\n",
            "317/317 - 1s - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.0277 - val_accuracy: 0.9963 - 916ms/epoch - 3ms/step\n",
            "Epoch 577/700\n",
            "317/317 - 1s - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0358 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 578/700\n",
            "317/317 - 1s - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.0242 - val_accuracy: 0.9981 - 956ms/epoch - 3ms/step\n",
            "Epoch 579/700\n",
            "317/317 - 1s - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0366 - val_accuracy: 0.9944 - 919ms/epoch - 3ms/step\n",
            "Epoch 580/700\n",
            "317/317 - 1s - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.0296 - val_accuracy: 0.9963 - 922ms/epoch - 3ms/step\n",
            "Epoch 581/700\n",
            "317/317 - 1s - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0240 - val_accuracy: 0.9925 - 921ms/epoch - 3ms/step\n",
            "Epoch 582/700\n",
            "317/317 - 1s - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0373 - val_accuracy: 0.9963 - 914ms/epoch - 3ms/step\n",
            "Epoch 583/700\n",
            "317/317 - 1s - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0366 - val_accuracy: 0.9963 - 915ms/epoch - 3ms/step\n",
            "Epoch 584/700\n",
            "317/317 - 1s - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.0324 - val_accuracy: 0.9963 - 932ms/epoch - 3ms/step\n",
            "Epoch 585/700\n",
            "317/317 - 1s - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0441 - val_accuracy: 0.9963 - 920ms/epoch - 3ms/step\n",
            "Epoch 586/700\n",
            "317/317 - 1s - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0363 - val_accuracy: 0.9944 - 912ms/epoch - 3ms/step\n",
            "Epoch 587/700\n",
            "317/317 - 1s - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0363 - val_accuracy: 0.9944 - 914ms/epoch - 3ms/step\n",
            "Epoch 588/700\n",
            "317/317 - 1s - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.0303 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 589/700\n",
            "317/317 - 1s - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.0322 - val_accuracy: 0.9906 - 916ms/epoch - 3ms/step\n",
            "Epoch 590/700\n",
            "317/317 - 1s - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.0416 - val_accuracy: 0.9944 - 915ms/epoch - 3ms/step\n",
            "Epoch 591/700\n",
            "317/317 - 1s - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0361 - val_accuracy: 0.9963 - 927ms/epoch - 3ms/step\n",
            "Epoch 592/700\n",
            "317/317 - 1s - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0356 - val_accuracy: 0.9963 - 919ms/epoch - 3ms/step\n",
            "Epoch 593/700\n",
            "317/317 - 1s - loss: 0.0085 - accuracy: 0.9967 - val_loss: 0.0345 - val_accuracy: 0.9944 - 941ms/epoch - 3ms/step\n",
            "Epoch 594/700\n",
            "317/317 - 1s - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0316 - val_accuracy: 0.9963 - 940ms/epoch - 3ms/step\n",
            "Epoch 595/700\n",
            "317/317 - 1s - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.0311 - val_accuracy: 0.9944 - 919ms/epoch - 3ms/step\n",
            "Epoch 596/700\n",
            "317/317 - 1s - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.0282 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 597/700\n",
            "317/317 - 1s - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0232 - val_accuracy: 0.9944 - 931ms/epoch - 3ms/step\n",
            "Epoch 598/700\n",
            "317/317 - 1s - loss: 0.0078 - accuracy: 0.9966 - val_loss: 0.0333 - val_accuracy: 0.9944 - 944ms/epoch - 3ms/step\n",
            "Epoch 599/700\n",
            "317/317 - 1s - loss: 0.0090 - accuracy: 0.9959 - val_loss: 0.0271 - val_accuracy: 0.9925 - 923ms/epoch - 3ms/step\n",
            "Epoch 600/700\n",
            "317/317 - 1s - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0369 - val_accuracy: 0.9944 - 919ms/epoch - 3ms/step\n",
            "Epoch 601/700\n",
            "317/317 - 1s - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0325 - val_accuracy: 0.9963 - 920ms/epoch - 3ms/step\n",
            "Epoch 602/700\n",
            "317/317 - 1s - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0410 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 603/700\n",
            "317/317 - 1s - loss: 0.0119 - accuracy: 0.9952 - val_loss: 0.0318 - val_accuracy: 0.9944 - 933ms/epoch - 3ms/step\n",
            "Epoch 604/700\n",
            "317/317 - 1s - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0281 - val_accuracy: 0.9944 - 916ms/epoch - 3ms/step\n",
            "Epoch 605/700\n",
            "317/317 - 1s - loss: 0.0059 - accuracy: 0.9972 - val_loss: 0.0225 - val_accuracy: 0.9963 - 921ms/epoch - 3ms/step\n",
            "Epoch 606/700\n",
            "317/317 - 1s - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.0361 - val_accuracy: 0.9944 - 907ms/epoch - 3ms/step\n",
            "Epoch 607/700\n",
            "317/317 - 1s - loss: 0.0086 - accuracy: 0.9965 - val_loss: 0.0305 - val_accuracy: 0.9944 - 933ms/epoch - 3ms/step\n",
            "Epoch 608/700\n",
            "317/317 - 1s - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0278 - val_accuracy: 0.9944 - 914ms/epoch - 3ms/step\n",
            "Epoch 609/700\n",
            "317/317 - 1s - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.0263 - val_accuracy: 0.9963 - 913ms/epoch - 3ms/step\n",
            "Epoch 610/700\n",
            "317/317 - 1s - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.0375 - val_accuracy: 0.9944 - 940ms/epoch - 3ms/step\n",
            "Epoch 611/700\n",
            "317/317 - 1s - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0324 - val_accuracy: 0.9944 - 931ms/epoch - 3ms/step\n",
            "Epoch 612/700\n",
            "317/317 - 1s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0320 - val_accuracy: 0.9906 - 920ms/epoch - 3ms/step\n",
            "Epoch 613/700\n",
            "317/317 - 1s - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.0225 - val_accuracy: 0.9981 - 914ms/epoch - 3ms/step\n",
            "Epoch 614/700\n",
            "317/317 - 1s - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0351 - val_accuracy: 0.9963 - 918ms/epoch - 3ms/step\n",
            "Epoch 615/700\n",
            "317/317 - 1s - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0301 - val_accuracy: 0.9963 - 914ms/epoch - 3ms/step\n",
            "Epoch 616/700\n",
            "317/317 - 1s - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0316 - val_accuracy: 0.9944 - 911ms/epoch - 3ms/step\n",
            "Epoch 617/700\n",
            "317/317 - 1s - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0241 - val_accuracy: 0.9963 - 913ms/epoch - 3ms/step\n",
            "Epoch 618/700\n",
            "317/317 - 1s - loss: 0.0035 - accuracy: 0.9983 - val_loss: 0.0341 - val_accuracy: 0.9925 - 934ms/epoch - 3ms/step\n",
            "Epoch 619/700\n",
            "317/317 - 1s - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.0411 - val_accuracy: 0.9963 - 939ms/epoch - 3ms/step\n",
            "Epoch 620/700\n",
            "317/317 - 1s - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0407 - val_accuracy: 0.9944 - 910ms/epoch - 3ms/step\n",
            "Epoch 621/700\n",
            "317/317 - 1s - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0335 - val_accuracy: 0.9944 - 924ms/epoch - 3ms/step\n",
            "Epoch 622/700\n",
            "317/317 - 1s - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.0256 - val_accuracy: 0.9963 - 921ms/epoch - 3ms/step\n",
            "Epoch 623/700\n",
            "317/317 - 1s - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.0309 - val_accuracy: 0.9963 - 921ms/epoch - 3ms/step\n",
            "Epoch 624/700\n",
            "317/317 - 1s - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0336 - val_accuracy: 0.9963 - 921ms/epoch - 3ms/step\n",
            "Epoch 625/700\n",
            "317/317 - 1s - loss: 0.0059 - accuracy: 0.9973 - val_loss: 0.0220 - val_accuracy: 0.9963 - 911ms/epoch - 3ms/step\n",
            "Epoch 626/700\n",
            "317/317 - 1s - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0247 - val_accuracy: 0.9944 - 940ms/epoch - 3ms/step\n",
            "Epoch 627/700\n",
            "317/317 - 1s - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0274 - val_accuracy: 0.9944 - 905ms/epoch - 3ms/step\n",
            "Epoch 628/700\n",
            "317/317 - 1s - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0255 - val_accuracy: 0.9963 - 963ms/epoch - 3ms/step\n",
            "Epoch 629/700\n",
            "317/317 - 1s - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.0329 - val_accuracy: 0.9963 - 932ms/epoch - 3ms/step\n",
            "Epoch 630/700\n",
            "317/317 - 1s - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0364 - val_accuracy: 0.9963 - 948ms/epoch - 3ms/step\n",
            "Epoch 631/700\n",
            "317/317 - 1s - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0383 - val_accuracy: 0.9963 - 939ms/epoch - 3ms/step\n",
            "Epoch 632/700\n",
            "317/317 - 1s - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0241 - val_accuracy: 0.9981 - 1s/epoch - 4ms/step\n",
            "Epoch 633/700\n",
            "317/317 - 1s - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.0182 - val_accuracy: 0.9963 - 1s/epoch - 4ms/step\n",
            "Epoch 634/700\n",
            "317/317 - 1s - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.0130 - val_accuracy: 0.9963 - 933ms/epoch - 3ms/step\n",
            "Epoch 635/700\n",
            "317/317 - 1s - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0334 - val_accuracy: 0.9963 - 925ms/epoch - 3ms/step\n",
            "Epoch 636/700\n",
            "317/317 - 1s - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.0338 - val_accuracy: 0.9944 - 912ms/epoch - 3ms/step\n",
            "Epoch 637/700\n",
            "317/317 - 1s - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.0265 - val_accuracy: 0.9963 - 921ms/epoch - 3ms/step\n",
            "Epoch 638/700\n",
            "317/317 - 1s - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0346 - val_accuracy: 0.9963 - 908ms/epoch - 3ms/step\n",
            "Epoch 639/700\n",
            "317/317 - 1s - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0333 - val_accuracy: 0.9963 - 931ms/epoch - 3ms/step\n",
            "Epoch 640/700\n",
            "317/317 - 1s - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0248 - val_accuracy: 0.9963 - 931ms/epoch - 3ms/step\n",
            "Epoch 641/700\n",
            "317/317 - 1s - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0267 - val_accuracy: 0.9944 - 927ms/epoch - 3ms/step\n",
            "Epoch 642/700\n",
            "317/317 - 1s - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0277 - val_accuracy: 0.9925 - 926ms/epoch - 3ms/step\n",
            "Epoch 643/700\n",
            "317/317 - 1s - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.0243 - val_accuracy: 0.9944 - 928ms/epoch - 3ms/step\n",
            "Epoch 644/700\n",
            "317/317 - 1s - loss: 0.0050 - accuracy: 0.9980 - val_loss: 0.0308 - val_accuracy: 0.9944 - 919ms/epoch - 3ms/step\n",
            "Epoch 645/700\n",
            "317/317 - 1s - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0266 - val_accuracy: 0.9963 - 938ms/epoch - 3ms/step\n",
            "Epoch 646/700\n",
            "317/317 - 1s - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0355 - val_accuracy: 0.9944 - 918ms/epoch - 3ms/step\n",
            "Epoch 647/700\n",
            "317/317 - 1s - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0306 - val_accuracy: 0.9963 - 928ms/epoch - 3ms/step\n",
            "Epoch 648/700\n",
            "317/317 - 1s - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0232 - val_accuracy: 0.9963 - 927ms/epoch - 3ms/step\n",
            "Epoch 649/700\n",
            "317/317 - 1s - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0391 - val_accuracy: 0.9925 - 919ms/epoch - 3ms/step\n",
            "Epoch 650/700\n",
            "317/317 - 1s - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.0300 - val_accuracy: 0.9963 - 940ms/epoch - 3ms/step\n",
            "Epoch 651/700\n",
            "317/317 - 1s - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.0696 - val_accuracy: 0.9888 - 940ms/epoch - 3ms/step\n",
            "Epoch 652/700\n",
            "317/317 - 1s - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.0314 - val_accuracy: 0.9963 - 936ms/epoch - 3ms/step\n",
            "Epoch 653/700\n",
            "317/317 - 1s - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0348 - val_accuracy: 0.9925 - 924ms/epoch - 3ms/step\n",
            "Epoch 654/700\n",
            "317/317 - 1s - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.0328 - val_accuracy: 0.9963 - 922ms/epoch - 3ms/step\n",
            "Epoch 655/700\n",
            "317/317 - 1s - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0301 - val_accuracy: 0.9944 - 943ms/epoch - 3ms/step\n",
            "Epoch 656/700\n",
            "317/317 - 1s - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0375 - val_accuracy: 0.9925 - 929ms/epoch - 3ms/step\n",
            "Epoch 657/700\n",
            "317/317 - 1s - loss: 0.0027 - accuracy: 0.9987 - val_loss: 0.0313 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 658/700\n",
            "317/317 - 1s - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0282 - val_accuracy: 0.9981 - 931ms/epoch - 3ms/step\n",
            "Epoch 659/700\n",
            "317/317 - 1s - loss: 0.0064 - accuracy: 0.9973 - val_loss: 0.0252 - val_accuracy: 0.9944 - 935ms/epoch - 3ms/step\n",
            "Epoch 660/700\n",
            "317/317 - 1s - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0279 - val_accuracy: 0.9963 - 919ms/epoch - 3ms/step\n",
            "Epoch 661/700\n",
            "317/317 - 1s - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.0325 - val_accuracy: 0.9944 - 930ms/epoch - 3ms/step\n",
            "Epoch 662/700\n",
            "317/317 - 1s - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0366 - val_accuracy: 0.9944 - 943ms/epoch - 3ms/step\n",
            "Epoch 663/700\n",
            "317/317 - 1s - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0424 - val_accuracy: 0.9963 - 924ms/epoch - 3ms/step\n",
            "Epoch 664/700\n",
            "317/317 - 1s - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0324 - val_accuracy: 0.9944 - 919ms/epoch - 3ms/step\n",
            "Epoch 665/700\n",
            "317/317 - 1s - loss: 0.0061 - accuracy: 0.9971 - val_loss: 0.0367 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 666/700\n",
            "317/317 - 1s - loss: 0.0034 - accuracy: 0.9986 - val_loss: 0.0414 - val_accuracy: 0.9944 - 928ms/epoch - 3ms/step\n",
            "Epoch 667/700\n",
            "317/317 - 1s - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0363 - val_accuracy: 0.9944 - 952ms/epoch - 3ms/step\n",
            "Epoch 668/700\n",
            "317/317 - 1s - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0265 - val_accuracy: 0.9944 - 938ms/epoch - 3ms/step\n",
            "Epoch 669/700\n",
            "317/317 - 1s - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.0299 - val_accuracy: 0.9906 - 931ms/epoch - 3ms/step\n",
            "Epoch 670/700\n",
            "317/317 - 1s - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0438 - val_accuracy: 0.9963 - 934ms/epoch - 3ms/step\n",
            "Epoch 671/700\n",
            "317/317 - 1s - loss: 0.0052 - accuracy: 0.9978 - val_loss: 0.0213 - val_accuracy: 0.9963 - 934ms/epoch - 3ms/step\n",
            "Epoch 672/700\n",
            "317/317 - 1s - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0255 - val_accuracy: 0.9963 - 945ms/epoch - 3ms/step\n",
            "Epoch 673/700\n",
            "317/317 - 1s - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0323 - val_accuracy: 0.9944 - 921ms/epoch - 3ms/step\n",
            "Epoch 674/700\n",
            "317/317 - 1s - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0560 - val_accuracy: 0.9850 - 943ms/epoch - 3ms/step\n",
            "Epoch 675/700\n",
            "317/317 - 1s - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0402 - val_accuracy: 0.9944 - 955ms/epoch - 3ms/step\n",
            "Epoch 676/700\n",
            "317/317 - 1s - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0410 - val_accuracy: 0.9944 - 947ms/epoch - 3ms/step\n",
            "Epoch 677/700\n",
            "317/317 - 1s - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0364 - val_accuracy: 0.9963 - 932ms/epoch - 3ms/step\n",
            "Epoch 678/700\n",
            "317/317 - 1s - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0278 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 679/700\n",
            "317/317 - 1s - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0360 - val_accuracy: 0.9963 - 932ms/epoch - 3ms/step\n",
            "Epoch 680/700\n",
            "317/317 - 1s - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0313 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 681/700\n",
            "317/317 - 1s - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0414 - val_accuracy: 0.9963 - 947ms/epoch - 3ms/step\n",
            "Epoch 682/700\n",
            "317/317 - 1s - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0467 - val_accuracy: 0.9944 - 936ms/epoch - 3ms/step\n",
            "Epoch 683/700\n",
            "317/317 - 1s - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.0394 - val_accuracy: 0.9963 - 927ms/epoch - 3ms/step\n",
            "Epoch 684/700\n",
            "317/317 - 1s - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0421 - val_accuracy: 0.9925 - 913ms/epoch - 3ms/step\n",
            "Epoch 685/700\n",
            "317/317 - 1s - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0331 - val_accuracy: 0.9944 - 921ms/epoch - 3ms/step\n",
            "Epoch 686/700\n",
            "317/317 - 1s - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0356 - val_accuracy: 0.9944 - 927ms/epoch - 3ms/step\n",
            "Epoch 687/700\n",
            "317/317 - 1s - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.0442 - val_accuracy: 0.9925 - 930ms/epoch - 3ms/step\n",
            "Epoch 688/700\n",
            "317/317 - 1s - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0479 - val_accuracy: 0.9944 - 929ms/epoch - 3ms/step\n",
            "Epoch 689/700\n",
            "317/317 - 1s - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.0373 - val_accuracy: 0.9944 - 923ms/epoch - 3ms/step\n",
            "Epoch 690/700\n",
            "317/317 - 1s - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0283 - val_accuracy: 0.9925 - 921ms/epoch - 3ms/step\n",
            "Epoch 691/700\n",
            "317/317 - 1s - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0357 - val_accuracy: 0.9944 - 922ms/epoch - 3ms/step\n",
            "Epoch 692/700\n",
            "317/317 - 1s - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0439 - val_accuracy: 0.9888 - 929ms/epoch - 3ms/step\n",
            "Epoch 693/700\n",
            "317/317 - 1s - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0336 - val_accuracy: 0.9944 - 925ms/epoch - 3ms/step\n",
            "Epoch 694/700\n",
            "317/317 - 1s - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.0354 - val_accuracy: 0.9944 - 925ms/epoch - 3ms/step\n",
            "Epoch 695/700\n",
            "317/317 - 1s - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0475 - val_accuracy: 0.9888 - 924ms/epoch - 3ms/step\n",
            "Epoch 696/700\n",
            "317/317 - 1s - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0409 - val_accuracy: 0.9963 - 926ms/epoch - 3ms/step\n",
            "Epoch 697/700\n",
            "317/317 - 1s - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0304 - val_accuracy: 0.9963 - 930ms/epoch - 3ms/step\n",
            "Epoch 698/700\n",
            "317/317 - 1s - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.0225 - val_accuracy: 0.9963 - 940ms/epoch - 3ms/step\n",
            "Epoch 699/700\n",
            "317/317 - 1s - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0390 - val_accuracy: 0.9963 - 940ms/epoch - 3ms/step\n",
            "Epoch 700/700\n",
            "317/317 - 1s - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0324 - val_accuracy: 0.9963 - 922ms/epoch - 3ms/step\n",
            "time: 655.918377161026\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 0.1243 - accuracy: 0.9839\n",
            "\n",
            "test accuracy: 98.39%\n",
            "test_accuracies: [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.98391926], dtype=float32)>]\n",
            "mean accuracy: [<tf.Tensor: shape=(), dtype=float32, numpy=0.98391926>]\n",
            "total_time: [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([655.9184], dtype=float32)>]\n",
            "mean time: [<tf.Tensor: shape=(), dtype=float32, numpy=655.9184>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" TRAIN/VALIDATION EVOLUTION PLOT \"\"\"\n",
        "evolution_curves_plot(history=history, language='en')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "rN9hm9dsGIM3",
        "outputId": "32ab2d2d-45a3-4120-a29e-f361480c1866"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" CONFUSION MATRIX PLOT \"\"\"\n",
        "\n",
        "confusion_matrix_plot(data=input_test, y_test=y_test, model=model, language='en')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "UXhMMrucGJT3",
        "outputId": "1cfa7bd5-e2cc-435f-c50d-f15715da3042"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "366/366 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" FREQUENCY LAYER WEIGHTS PLOT \"\"\"\n",
        "\n",
        "freq_weights_plot(model=model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "zahSSmJaGWRT",
        "outputId": "a4e01c1f-5ba9-46f5-9156-87d75641d8d8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpwXxyqpGaOK",
        "outputId": "81122cea-f4e2-4cef-ec33-3d023fa2f3e3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " freq_layer (FreqLayer)      (None, 5376)              5376      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                344128    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 352,706\n",
            "Trainable params: 352,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}