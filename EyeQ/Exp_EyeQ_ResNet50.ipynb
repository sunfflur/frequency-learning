{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "smXRCRKE3gGt",
        "Bu99OidX-urG",
        "M_s5caaLiTaM",
        "l_r-5JokgxFR",
        "DJORaKeEjcUi"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPCjdNbexDRaAh/bY+a+cqK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunfflur/frequency-learning/blob/master/EyeQ/Exp_EyeQ_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50V2"
      ],
      "metadata": {
        "id": "p7l7rPShHiWE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smXRCRKE3gGt"
      },
      "source": [
        "#### Libraries Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oot4s_fB3W5F",
        "outputId": "0183874b-b5d6-49c8-bdbb-8b2cfd35f057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-recommenders in /usr/local/lib/python3.7/dist-packages (0.7.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-recommenders) (1.3.0)\n",
            "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-recommenders) (2.9.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.1.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.2.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.50.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (4.1.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (14.0.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (21.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.21.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.27.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow-recommenders) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.9.0->tensorflow-recommenders) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow>=2.9.0->tensorflow-recommenders) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "s = 23\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(s)\n",
        "import random\n",
        "random.seed(s)\n",
        "from numpy.random import seed\n",
        "seed(s)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(s)\n",
        "\n",
        "import PIL\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, Conv1D, Dropout, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from tensorflow.keras.applications.vgg16 import VGG16\n",
        "#from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "!pip install tensorflow-addons \n",
        "!pip install tensorflow-recommenders\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n0D9z1XL5xV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c915cd2-6591-4bc4-aa9b-5a84937cd785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov  3 00:23:07 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tk7Kjs6Mmsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8862943e-d3e2-4a98-f303-200c70c93431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Drive mount"
      ],
      "metadata": {
        "id": "Bu99OidX-urG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TESSSSSST ###\n",
        "\n",
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ],
      "metadata": {
        "id": "je242-LYOKFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "057d2fc2-fabc-40f4-eea8-113ea79096dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: www-browser: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links2: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: elinks: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: lynx: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=TfkwoGsBlax0J4K8CZYP5EoSLXYt0J%2FEEMdmn8qK6EM'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=TfkwoGsBlax0J4K8CZYP5EoSLXYt0J%2FEEMdmn8qK6EM\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBjc7IqP3wqU",
        "outputId": "7a0947a2-c240-4c76-8735-f41c69ed2c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package w3m.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 123947 files and directories currently installed.)\n",
            "Preparing to unpack .../w3m_0.5.3-36build1_amd64.deb ...\n",
            "Unpacking w3m (0.5.3-36build1) ...\n",
            "Setting up w3m (0.5.3-36build1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Load"
      ],
      "metadata": {
        "id": "M_s5caaLiTaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### data loading ### \n",
        "with tf.device('/CPU:0'):\n",
        "  xm1 = tf.data.experimental.load('/content/drive/MyDrive/Mestrado/Datasets/drd/train data/xm1')\n",
        "  xm2 = tf.data.experimental.load('/content/drive/MyDrive/Mestrado/Datasets/drd/train data/xm2')\n",
        "  xmt1 = tf.data.experimental.load('/content/drive/MyDrive/Mestrado/Datasets/drd/test data/xmt1')\n",
        "  xmt2 = tf.data.experimental.load('/content/drive/MyDrive/Mestrado/Datasets/drd/test data/xmt2')\n",
        "  \n",
        "  #concatenate them\n",
        "  x_train = xm1.concatenate(xm2) #data between 0,1\n",
        "  x_test = xmt1.concatenate(xmt2) #data between 0,1"
      ],
      "metadata": {
        "id": "sKlHUxwXiWsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### preprocess"
      ],
      "metadata": {
        "id": "l_r-5JokgxFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation split"
      ],
      "metadata": {
        "id": "W6fWeefCmVhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ds_split(ds, ds_size, train_split=0.9, val_split=0.1, shuffle=False, shuffle_size=None):\n",
        "    assert (train_split + val_split) == 1\n",
        "    \n",
        "    if shuffle:\n",
        "        # Specify seed to always have the same split distribution between runs\n",
        "        ds = ds.shuffle(shuffle_size, seed=11)\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    #test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds"
      ],
      "metadata": {
        "id": "x5FXFb63mdW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_x, x_val_x = ds_split(x_train, 10667)"
      ],
      "metadata": {
        "id": "M9wd8aPsm8Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xUp4kf5cTMg",
        "outputId": "31b12f42-2263-4a30-e1a4-99fa679b7c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=(TensorSpec(shape=(224, 224, 3), dtype=tf.float64, name=None), TensorSpec(shape=(2,), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train1 = x_train_x.map(lambda x,y: (preprocess_input(x*255),y), num_parallel_calls=tf.data.AUTOTUNE).shuffle(300).batch(32, drop_remainder=True).cache()\n",
        "x_train1 = x_train1.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "nJDFVV9g6o_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.data.get_output_shapes(x_train1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTuQ8s_u9iDZ",
        "outputId": "f9c6e4c6-74eb-4f24-ce44-fcecaa282fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([32, 224, 224, 3]), TensorShape([32, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val1 = x_val_x.map(lambda x,y: (preprocess_input(x*255),y), num_parallel_calls=tf.data.AUTOTUNE).batch(32, drop_remainder=True).cache()\n",
        "x_val1 = x_val1.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "F6BUA3tPpAkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.data.get_output_shapes(x_val1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ZwunpFpHVJ",
        "outputId": "4e5b506b-a457-432d-b539-986d98713fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([32, 224, 224, 3]), TensorShape([32, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test1 = x_test.map(lambda z, y: (preprocess_input(z*255), y), num_parallel_calls=tf.data.AUTOTUNE).batch(32, drop_remainder=True).cache()\n",
        "x_test1 = x_test1.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "pBx-1SoL7A-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.data.get_output_shapes(x_test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEBoYaS_Kcss",
        "outputId": "dba76966-a614-42f7-8ac1-df9d149778c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([32, 224, 224, 3]), TensorShape([32, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pre-trained Model"
      ],
      "metadata": {
        "id": "DJORaKeEjcUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_trained_model(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. \n",
        "               0 = all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    resnet50_model = ResNet50V2(include_top=True,\n",
        "                     weights='imagenet', \n",
        "                     input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    \n",
        "    if fine_tune > 0:\n",
        "        for layer in resnet50_model.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in resnet50_model.layers:\n",
        "            layer.trainable = False\n",
        "    '''\n",
        "    for layer in resnet50_model.layers:\n",
        "      layer.trainable = True\n",
        "    '''\n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = resnet50_model.layers[-2].output\n",
        "    #top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    #top_model = Dense(4096, activation='relu')(top_model)\n",
        "    #top_model = Dense(128, activation='relu')(top_model)\n",
        "    #top_model = Dropout(0.25)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax', name='my_predictions')(top_model)\n",
        "    \n",
        "    # Group the convolutional base and new output into a Model object.\n",
        "    model = Model(inputs=resnet50_model.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "7RwEJmvLjdz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(s) #s\n",
        "opt = Adam(learning_rate=0.001)\n",
        "ResNet50_model = pre_trained_model(input_shape=(224,224,3), n_classes=2, optimizer=opt)"
      ],
      "metadata": {
        "id": "LqpIuR1tw3yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ResNet50_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyjW7_mQBET",
        "outputId": "377c423f-eae5-4dbd-ba80-6e6745733d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 28, 28, 256)  0           ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['post_relu[0][0]']              \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " my_predictions (Dense)         (None, 2)            4098        ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,568,898\n",
            "Trainable params: 4,098\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ModelCheckpoint callback - save best weights\n",
        "estopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Mestrado/Experimentos/exp-eyeq/exp-eyeq-pynb/model_resnet50_pt.weights.best.hdf5', save_best_only=True, verbose=0)\n",
        "history = ResNet50_model.fit(x_train1, epochs=100, verbose=1, validation_data=x_val1, callbacks=[checkpoint, estopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysurod4VoUZ4",
        "outputId": "aaf2cd87-17a7-465f-d71e-fa6b23257e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "300/300 [==============================] - 364s 963ms/step - loss: 0.0911 - accuracy: 0.9677 - val_loss: 0.0483 - val_accuracy: 0.9848\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - 38s 128ms/step - loss: 0.0435 - accuracy: 0.9852 - val_loss: 0.0417 - val_accuracy: 0.9858\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - 36s 119ms/step - loss: 0.0344 - accuracy: 0.9880 - val_loss: 0.0390 - val_accuracy: 0.9886\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - 38s 128ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.0372 - val_accuracy: 0.9886\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - 35s 118ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.0359 - val_accuracy: 0.9886\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - 38s 126ms/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.0349 - val_accuracy: 0.9896\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - 35s 116ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0342 - val_accuracy: 0.9896\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - 37s 124ms/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.0336 - val_accuracy: 0.9896\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - 35s 117ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.0332 - val_accuracy: 0.9905\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - 38s 128ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.0329 - val_accuracy: 0.9905\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - 35s 117ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.0327 - val_accuracy: 0.9905\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0327 - val_accuracy: 0.9915\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0329 - val_accuracy: 0.9915\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0334 - val_accuracy: 0.9915\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0340 - val_accuracy: 0.9915\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0349 - val_accuracy: 0.9915\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.0359 - val_accuracy: 0.9915\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0371 - val_accuracy: 0.9915\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - 30s 100ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.0382 - val_accuracy: 0.9915\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - 30s 100ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0392 - val_accuracy: 0.9915\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.0401 - val_accuracy: 0.9915\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 0.0408 - val_accuracy: 0.9915\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0415 - val_accuracy: 0.9915\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0422 - val_accuracy: 0.9905\n",
            "Epoch 25/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.0428 - val_accuracy: 0.9905\n",
            "Epoch 26/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0431 - val_accuracy: 0.9905\n",
            "Epoch 27/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0430 - val_accuracy: 0.9905\n",
            "Epoch 28/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0425 - val_accuracy: 0.9905\n",
            "Epoch 29/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0419 - val_accuracy: 0.9905\n",
            "Epoch 30/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.0413 - val_accuracy: 0.9905\n",
            "Epoch 31/100\n",
            "300/300 [==============================] - 30s 101ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0409 - val_accuracy: 0.9905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(121), plt.plot(history.history['loss'], label='loss')\n",
        "plt.subplot(121), plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Época', fontsize=12), plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Evolução da curva de perda')\n",
        "plt.legend()\n",
        "plt.subplot(122), plt.plot(history.history['accuracy'], label = 'accuracy', color='green')\n",
        "plt.subplot(122), plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Época', fontsize=12), plt.ylabel('Acc', fontsize=12)\n",
        "plt.title('Evolução da curva de acurácia')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "sty7pveTxV3Z",
        "outputId": "29cf59ab-8cf9-4e00-e791-2ca31f0c47d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50_model.load_weights('/content/drive/MyDrive/Mestrado/Experimentos/exp-eyeq/exp-eyeq-pynb/model_resnet50_pt.weights.best.hdf5')"
      ],
      "metadata": {
        "id": "i0sAvGcun_ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TEST ACC ###\n",
        "scores = ResNet50_model.evaluate(x_test1)\n",
        "print('\\n%s : %.2f%%' % (ResNet50_model.metrics_names[1], scores[1] * 100))"
      ],
      "metadata": {
        "id": "oxSpFAKlxVJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1445b0-ec25-4349-c4d8-832610bbb271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "365/365 [==============================] - 251s 471ms/step - loss: 0.0407 - accuracy: 0.9865\n",
            "\n",
            "accuracy : 98.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random initialization"
      ],
      "metadata": {
        "id": "2PiatLhZrTHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def non_pre_trained_model(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. \n",
        "               0 = all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    resnet50_model = ResNet50V2(include_top=True,\n",
        "                     weights=None, \n",
        "                     input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    '''\n",
        "    if fine_tune > 0:\n",
        "        for layer in resnet50_model.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in resnet50_model.layers:\n",
        "            layer.trainable = False\n",
        "    '''\n",
        "    for layer in resnet50_model.layers:\n",
        "      layer.trainable = True\n",
        "    \n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = resnet50_model.layers[-2].output\n",
        "    #top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    #top_model = Dense(4096, activation='relu')(top_model)\n",
        "    #top_model = Dense(128, activation='relu')(top_model)\n",
        "    #top_model = Dropout(0.25)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax', name='my_predictions')(top_model)\n",
        "    \n",
        "    # Group the convolutional base and new output into a Model object.\n",
        "    model = Model(inputs=resnet50_model.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "d5Nmdr5qrTHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(s) #s\n",
        "opt = Adam(learning_rate=0.001)\n",
        "ResNet50_model = non_pre_trained_model(input_shape=(224,224,3), n_classes=2, optimizer=opt)"
      ],
      "metadata": {
        "id": "z2fqmMShrTHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ResNet50_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "596b9876-1beb-45a5-c7eb-a8c0971fbca4",
        "id": "QgR35RkjrTHL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 28, 28, 256)  0           ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['post_relu[0][0]']              \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " my_predictions (Dense)         (None, 2)            4098        ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,568,898\n",
            "Trainable params: 23,523,458\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ModelCheckpoint callback - save best weights\n",
        "estopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Mestrado/Experimentos/exp-eyeq/exp-eyeq-pynb/model_resnet50_rdn.weights.best.hdf5', save_best_only=True, verbose=0)\n",
        "history = ResNet50_model.fit(x_train1, epochs=100, verbose=1, validation_data=x_val1, callbacks=[checkpoint, estopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c01592-fbf3-4e4f-e977-dbae2ef8a02d",
        "id": "0niBI-uQrTHL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "300/300 [==============================] - 401s 1s/step - loss: 0.2521 - accuracy: 0.9173 - val_loss: 0.3365 - val_accuracy: 0.9110\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - 88s 292ms/step - loss: 0.2021 - accuracy: 0.9344 - val_loss: 4.2251 - val_accuracy: 0.3163\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - 88s 294ms/step - loss: 0.1577 - accuracy: 0.9471 - val_loss: 0.4691 - val_accuracy: 0.8873\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - 100s 334ms/step - loss: 0.1258 - accuracy: 0.9551 - val_loss: 0.2523 - val_accuracy: 0.9195\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - 88s 294ms/step - loss: 0.1124 - accuracy: 0.9622 - val_loss: 0.2872 - val_accuracy: 0.9186\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - 88s 293ms/step - loss: 0.1017 - accuracy: 0.9639 - val_loss: 0.3271 - val_accuracy: 0.9138\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - 101s 337ms/step - loss: 0.0969 - accuracy: 0.9664 - val_loss: 0.2517 - val_accuracy: 0.9252\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - 88s 293ms/step - loss: 0.0901 - accuracy: 0.9699 - val_loss: 0.2974 - val_accuracy: 0.9280\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - 88s 292ms/step - loss: 0.0919 - accuracy: 0.9674 - val_loss: 0.3702 - val_accuracy: 0.9186\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - 88s 293ms/step - loss: 0.0818 - accuracy: 0.9718 - val_loss: 0.3453 - val_accuracy: 0.9290\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - 88s 293ms/step - loss: 0.0764 - accuracy: 0.9721 - val_loss: 0.2856 - val_accuracy: 0.9261\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - 100s 335ms/step - loss: 0.0703 - accuracy: 0.9753 - val_loss: 0.2226 - val_accuracy: 0.9470\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - 88s 293ms/step - loss: 0.0681 - accuracy: 0.9756 - val_loss: 0.5904 - val_accuracy: 0.9138\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - 88s 293ms/step - loss: 0.0625 - accuracy: 0.9786 - val_loss: 0.2658 - val_accuracy: 0.9441\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - 88s 293ms/step - loss: 0.0612 - accuracy: 0.9778 - val_loss: 0.3298 - val_accuracy: 0.9470\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - 88s 293ms/step - loss: 0.0543 - accuracy: 0.9814 - val_loss: 0.5921 - val_accuracy: 0.9205\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - 105s 349ms/step - loss: 0.0490 - accuracy: 0.9835 - val_loss: 0.2190 - val_accuracy: 0.9517\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - 102s 339ms/step - loss: 0.0466 - accuracy: 0.9853 - val_loss: 0.1598 - val_accuracy: 0.9574\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - 88s 292ms/step - loss: 0.0423 - accuracy: 0.9866 - val_loss: 0.2657 - val_accuracy: 0.9498\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - 88s 292ms/step - loss: 0.0402 - accuracy: 0.9861 - val_loss: 0.1648 - val_accuracy: 0.9650\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 0.4564 - val_accuracy: 0.9403\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 0.1744 - val_accuracy: 0.9688\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - 87s 292ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.2281 - val_accuracy: 0.9631\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0339 - accuracy: 0.9879 - val_loss: 0.1942 - val_accuracy: 0.9602\n",
            "Epoch 25/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 0.2132 - val_accuracy: 0.9593\n",
            "Epoch 26/100\n",
            "300/300 [==============================] - 87s 292ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.2039 - val_accuracy: 0.9621\n",
            "Epoch 27/100\n",
            "300/300 [==============================] - 100s 332ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.0785 - val_accuracy: 0.9754\n",
            "Epoch 28/100\n",
            "300/300 [==============================] - 88s 292ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.0816 - val_accuracy: 0.9754\n",
            "Epoch 29/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.1647 - val_accuracy: 0.9716\n",
            "Epoch 30/100\n",
            "300/300 [==============================] - 101s 337ms/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0768 - val_accuracy: 0.9830\n",
            "Epoch 31/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.1065 - val_accuracy: 0.9782\n",
            "Epoch 32/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0250 - accuracy: 0.9907 - val_loss: 0.0876 - val_accuracy: 0.9811\n",
            "Epoch 33/100\n",
            "300/300 [==============================] - 101s 336ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.0644 - val_accuracy: 0.9848\n",
            "Epoch 34/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.1434 - val_accuracy: 0.9735\n",
            "Epoch 35/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0663 - val_accuracy: 0.9848\n",
            "Epoch 36/100\n",
            "300/300 [==============================] - 87s 290ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.3572 - val_accuracy: 0.9290\n",
            "Epoch 37/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.1923 - val_accuracy: 0.9640\n",
            "Epoch 38/100\n",
            "300/300 [==============================] - 101s 337ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0598 - val_accuracy: 0.9801\n",
            "Epoch 39/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0803 - val_accuracy: 0.9782\n",
            "Epoch 40/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0091 - accuracy: 0.9962 - val_loss: 0.0950 - val_accuracy: 0.9754\n",
            "Epoch 41/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0173 - accuracy: 0.9935 - val_loss: 0.1147 - val_accuracy: 0.9811\n",
            "Epoch 42/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1027 - val_accuracy: 0.9801\n",
            "Epoch 43/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.1777 - val_accuracy: 0.9754\n",
            "Epoch 44/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0935 - val_accuracy: 0.9830\n",
            "Epoch 45/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.2080 - val_accuracy: 0.9545\n",
            "Epoch 46/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0952 - val_accuracy: 0.9792\n",
            "Epoch 47/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0889 - val_accuracy: 0.9801\n",
            "Epoch 48/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1673 - val_accuracy: 0.9669\n",
            "Epoch 49/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.1190 - val_accuracy: 0.9839\n",
            "Epoch 50/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0859 - val_accuracy: 0.9839\n",
            "Epoch 51/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0982 - val_accuracy: 0.9650\n",
            "Epoch 52/100\n",
            "300/300 [==============================] - 87s 292ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0967 - val_accuracy: 0.9830\n",
            "Epoch 53/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0928 - val_accuracy: 0.9820\n",
            "Epoch 54/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.2079 - val_accuracy: 0.9744\n",
            "Epoch 55/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 6.9150 - val_accuracy: 0.5284\n",
            "Epoch 56/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.1367 - val_accuracy: 0.9773\n",
            "Epoch 57/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1015 - val_accuracy: 0.9782\n",
            "Epoch 58/100\n",
            "300/300 [==============================] - 87s 291ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1558 - val_accuracy: 0.9782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(121), plt.plot(history.history['loss'], label='loss')\n",
        "plt.subplot(121), plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Época', fontsize=12), plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Evolução da curva de perda')\n",
        "plt.legend()\n",
        "plt.subplot(122), plt.plot(history.history['accuracy'], label = 'accuracy', color='green')\n",
        "plt.subplot(122), plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Época', fontsize=12), plt.ylabel('Acc', fontsize=12)\n",
        "plt.title('Evolução da curva de acurácia')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "dc7f0a95-f8e7-4f98-e837-936c38f2dd30",
        "id": "AcShJFE9rTHL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50_model.load_weights('/content/drive/MyDrive/Mestrado/Experimentos/exp-eyeq/exp-eyeq-pynb/model_resnet50_rdn.weights.best.hdf5')"
      ],
      "metadata": {
        "id": "J2S9Wx5rrTHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TEST ACC ###\n",
        "scores = ResNet50_model.evaluate(x_test1)\n",
        "print('\\n%s : %.2f%%' % (ResNet50_model.metrics_names[1], scores[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493cbf41-d653-4948-916a-b76da62c87f6",
        "id": "De4sQd_drTHM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "365/365 [==============================] - 168s 355ms/step - loss: 0.1107 - accuracy: 0.9736\n",
            "\n",
            "accuracy : 97.36%\n"
          ]
        }
      ]
    }
  ]
}